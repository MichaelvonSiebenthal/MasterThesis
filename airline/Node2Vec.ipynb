{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fbd768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required packages\n",
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7735098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for scaling non-ordinal data within the range of 1 - 5 \n",
    "def normalize(x):\n",
    "    return (x-x.min())/(x.max()-x.min()) * (5-1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5cf5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DataFrame')\n",
    "X = pd.read_csv('clean_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bfef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "X.Class = X.Class.apply(lambda x: 1 if x == 0 else(2 if x == 1 else 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25589b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.Series(X.satisfaction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dce535",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var = X.drop(columns=['satisfaction'])\n",
    "x_wd = pd.get_dummies(data=x_var,columns=['Customer Type','Type of Travel','Gender'])\n",
    "x_wd[['Age','Departure Delay in Minutes','Flight Distance']] = normalize(x_wd[['Age','Departure Delay in Minutes','Flight Distance']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d31196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node2vec train data\n",
    "t = pd.read_csv('embeddings', delimiter = \" \", index_col=0, header = None)\n",
    "t.sort_index(inplace=True)\n",
    "t = t.to_numpy()\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc154b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pd.DataFrame(t,columns = ['x1','x2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde5b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node2vec train\n",
    "XXXX = x_wd.copy(deep=True)\n",
    "XXXX['z1'] = Z.x1\n",
    "XXXX['z2'] = Z.x2\n",
    "XXXX_label = pd.get_dummies(features)\n",
    "XXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e805830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node2vec test\n",
    "t_test = pd.read_csv('embeddings_test', delimiter = \" \", index_col=0, header = None)\n",
    "t_test.sort_index(inplace=True)\n",
    "t_test = t_test.to_numpy()\n",
    "t_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a719d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_test = pd.DataFrame(t_test,columns = ['x1','x2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v_test_df = pd.read_csv('TEST_DF')\n",
    "n2v_test_df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "n2v_test_label = n2v_test_df.satisfaction\n",
    "n2v_test_feats = n2v_test_df.drop(columns=['satisfaction'])\n",
    "n2v_test_feats_dummy = pd.get_dummies(data=n2v_test_feats,columns=['Customer Type','Type of Travel','Gender'])\n",
    "n2v_test_feats_dummy[['Age','Departure Delay in Minutes','Flight Distance']] = normalize(n2v_test_feats_dummy[['Age','Departure Delay in Minutes','Flight Distance']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TTTTTT_label = pd.get_dummies(n2v_test_label)\n",
    "TTTTTT_label_tf = tf.convert_to_tensor(TTTTTT_label)\n",
    "TTTTTT = n2v_test_feats_dummy.copy(deep=True)\n",
    "TTTTTT['z1'] = Z_test.x1\n",
    "TTTTTT['z2'] = Z_test.x2\n",
    "TTTTTT_tf = tf.convert_to_tensor(TTTTTT)\n",
    "TTTTTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753aaa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = sm.add_constant(t) \n",
    "log_reg = sm.Logit(features, P).fit()\n",
    "print(log_reg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c465cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = log_reg.predict(P) \n",
    "\n",
    "yhat_log = np.empty((len(predictions),1))\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] < 0.5:\n",
    "        yhat_log[i] = 0\n",
    "    else:         \n",
    "        yhat_log[i] = 1\n",
    "\n",
    "print('Classification Accuracy validation set {}'.format(accuracy_score(features,yhat_log)))\n",
    "print('-------------------------------------------------------------')\n",
    "print('Confusion Matrix validation set:')\n",
    "print(confusion_matrix(features,yhat_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c2cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(XXXX,XXXX_label, test_size = 0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tf = tf.convert_to_tensor(x_train)\n",
    "x_test_tf = tf.convert_to_tensor(x_test)\n",
    "y_train_tf = tf.convert_to_tensor(y_train)\n",
    "y_test_tf = tf.convert_to_tensor(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(15, activation='relu'))\n",
    "#model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "#opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(x_train_tf, y_train_tf,validation_data=(x_test_tf,y_test_tf), epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a7a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['loss'],label = 'Training Loss')\n",
    "plt.plot(history.history['val_loss'],label = 'Validation Loss')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Cross-Entropy Loss')\n",
    "plt.title('Loss per Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['accuracy'],label = 'Training accuracy')\n",
    "plt.plot(history.history['val_accuracy'],label = 'Validation accuracy')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy per Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ff2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(TTTTTT_tf, TTTTTT_label_tf)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53897835",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_y = np.empty((len(features),1))\n",
    "\n",
    "for i in range(len(features)):\n",
    "    if features.iloc[i] == 1:\n",
    "        svm_y[i] = 1\n",
    "    else:\n",
    "        svm_y[i] = -1\n",
    "\n",
    "svm_y.astype(int)\n",
    "x_train, x_test, y_train, y_test = train_test_split(XXXX,svm_y, test_size = 0.2, shuffle=True)\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(x_train, y_train)\n",
    "print(clf.score(x_train, y_train))\n",
    "print(clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f76c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_y_test = np.empty((len(n2v_test_label),1))\n",
    "\n",
    "for i in range(len(n2v_test_label)):\n",
    "    if n2v_test_label.iloc[i] == 1:\n",
    "        svm_y_test[i] = 1\n",
    "    else:\n",
    "        svm_y_test[i] = -1\n",
    "\n",
    "y_pred = clf.predict(TTTTTT)\n",
    "print(clf.score(TTTTTT, svm_y_test))\n",
    "print(sklearn.metrics.f1_score(y_pred, svm_y_test,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c6b00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=None, random_state=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(XXXX,svm_y, test_size = 0.2, shuffle=True)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "print(clf.score(x_train, y_train))\n",
    "print(clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bb88cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(TTTTTT)\n",
    "print(clf.score(TTTTTT, svm_y_test))\n",
    "print(sklearn.metrics.f1_score(y_pred, svm_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23297568",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0,max_iter=500).fit(x_train, y_train)\n",
    "y_pred = clf.predict(TTTTTT)\n",
    "print(clf.score(x_train, y_train))\n",
    "print(clf.score(x_test, y_test))\n",
    "print(clf.score(TTTTTT, svm_y_test))\n",
    "print(sklearn.metrics.f1_score(y_pred, svm_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9885859",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.scatterplot(x=Z.x1,y=Z.x2,hue=df['satisfaction'],alpha=0.8)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
