
  \section{Data}
  
  This section introduces the datasets used for this thesis. Several approaches
  and datasets were considered for the subsequent analysis. In particular, three
  datasets were considered with varying degrees of success which are:

  \begin{enumerate}
    \item Self launched survey
    \item Bank telemarketing dataset
    \item Airline passenger satisfaction survey
  \end{enumerate}

  \noindent The datasets are introduced in the following subsections to the
  extent that they were of use for the purpose of this thesis. In particular,
  the self launched survey and the bank telemarketing dataset showed to be
  problematic for different reasons. These two datasets are therefore briefly
  introduced and the results which highlight the difficulties of the datasets
  are shown directly. The detailed analyses of these two datasets are deferred
  to the appendix as the focus will be placed on the airline passenger
  satisfaction survey for which more promising results were achieved. 


  In the following subsections the different datasets are briefly 
  introduced and reasons for its use or non-use will be given.

  \subsection{Self Launched Survey}
  \label{section:self_survey}

  Initially, the aim was to make use of a self-launched survey which focused on
  a bank client classification task. The classification task was two-fold in 
  that a simpler task focused on classifying bank clients as to whether they 
  would be interested in investing or not. The second classification task
  involved classifying clients according to their investment preferences in
  terms of products (single securities like stocks or bonds, funds, ETFs,
  unsure). The variables used for the graph creation using the MAG model
  included mostly demographic data. Additional data was collected by assessing
  the financial knowledge and behavioral profile of the survey participants by 
  using questions from the financial literacy report of the OECD \citep{OECD2017}.
  It is suspected, that demographic data coupled with the financial literacy
  questions should be provide a suitable database for the bank client
  classification task given. This is based on the professional experience of
  the author of this thesis having worked for over 10 years as a client adviser
  for a large Swiss bank. \\

  \noindent Unfortunately, only $n=113$ people participated in the survey which 
  in general is very small for a machine learning task.
  Further, the graphs generated using the MAG method were not stable. Due to
  the stochastic element present in the MAG model, the resulting graphs could
  differ dramatically. This lead to significant performance differences for the
  different machine learning methods applied to the resulting graph.
  Classification accuracies ranged between accuracies of 40 - 95 \%. A remedy
  for this problem would be to assign a fixed probability threshold such as 0.5
  in the MAG model. In this setting, the graph generation would be
  deterministic, however it would ensure identical graph generation. The
  downside however is that the graph generation process is less realistic. In
  the homophily setting this would assume that a connection is formed with any
  node if the $P[u,v]>0.5$. From our shared human experience we know, that
  people often form friendships or other connections with people who can differ
  significantly to themselves. This raises the question as to whether we should
  care about the stochastic element involved in forming connections for a
  synthetically created graph for the purpose of a classification task? This is
  an important question which was discovered due to the small sample size of
  the self created survey and will be discussed in a subsequent subsection. 
  Due to the small sample size which makes the survey data inadequate for any
  meaningful machine learning task, the survey was finally discarded for
  further analysis for this thesis. In Appendix X an overview of the survey
  data is given. Further, the performed analyses for this dataset are provided
  in the accompanying git repository. Nevertheless, the survey can be taken as
  a model of how one could generate a dataset for the MAG model and subsequent
  graph machine learning. 


  \subsection{Bank Telemarketing Dataset}

  The bank telemarketing dataset first introduced in the article by
  \cite{moro2011using,moro2014data} was considered as an alternative back-up 
  dataset in case the self made survey did not yield a sufficient number of 
  responses. The bank telemarketing dataset is based on a marketing campaign at 
  a Portuguese bank. The dataset includes demographic data, data regarding the 
  bank client's wealth, information regarding the success of contacting the 
  client in previous campaigns and information such as the length of the 
  telephone conversation. The dataset further provides information as to whether 
  the campaign was successful in that the contacted client invested in a short-term 
  deposit which was being advertised in the telemarketing campaign. This is the
  label data and the dataset is thus staged as a binary classification task.
  The resulting MAG graphs is shown in figure \ref{fig:Moro}:
 
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.7\textwidth]{Moro_network.png}
		\caption{MAG graph of bank telemarketing dataset}
        \label{fig:Moro}
	\end{figure}
  
  \noindent The red dots in figure \ref{fig:Moro} mark the clients which
  decided to invest in the short-term deposit and the blue dots did not invest.
  While this figure masks some of the nodes due to the figure generation
  process, the general pattern becomes apparent. The red nodes appear to be 
  randomly placed in the network which suggests, that the demographic variables 
  which are suitable and were used for the MAG generation process do not
  capture the structure of the label well. The graph further shows, that only a
  relatively small number of clients appear to have invested in the short-term
  deposit. To be more precise, in the dataset only consists of approximately 
  12\% of bank clients which invested in the short-term deposit. The dataset is 
  therefore relatively unbalanced which makes the classification task rather 
  difficult. Graph representation learning using Node2Vec did not provide any 
  useful results and the GNNs also performed rather poorly. In particular, GNNs 
  tendedto classify most clients as non-investors and struggled to accurately
  classify clients which did invest. Due to the unbalanced label data, it was
  loss optimizing to predict most nodes as non-investors rather than learning
  the true observations. Table \ref{table:Moro_conf} shows the confusion matrix
  of the model classifications for the validation data (20\%) using a GraphSage
  GNN.

  \begin{table}[h]
    \centering
    \begin{tabular}{|l|l|c|c}
      \hline
      \diagbox{Label}{Predicted} & Did not invest & Invested \\
      \hline
      Did not invest & 1'026 & 30 \\ 
      Invested & 119 & 33 \\
      \hline
    \end{tabular}
    \caption{Confusion Matrix Validation Bank Telemarketing Data}
    \label{table:Moro_conf}
  \end{table}


  \noindent The resulting confusion matrix corresponds to an accuracy of
  approximately 87.67\%. The graph generation and subsequent model fitting was
  repeated several times and the accuracies all ranged between 87-90\%. This 
  behavior was observed for both graph based methods and standard machine 
  learning approaches such as ANN or support vector machines (SVM). \\

  \noindent This is part of a larger and common problem in machine learning. 
  Possible remedies might include using loss functions which penalize 
  false classifications harsher than the standard cross entropy loss function
  used for the GNNs. Alternatively one could also reduce the data set by 
  dropping observations such that the remaining dataset is balanced. This 
  approach has its own problem as dropping a large number of observation 
  discards a lot of potentially valuable information. It could also put in 
  question the external validity of the model. These comments point to a 
  separate field of research and could be interesting for a future project. 
  These approaches were not researched in detail and should be taken as 
  suggestions. This thesis will not focus on this problem which is why this 
  issue is not further investigated. \\

  \noindent The failure using graph machine learning methods for this dataset
  reveals, that GNNs are not an easy remedy for unbalanced data. Perhaps if the
  network structure provided clusters which corresponded to the labels, GNNs
  could provide superior results. Given the variables available in the dataset
  and the limitations of using the MAG method, this was not possible. In order
  to check, whether network structure could indeed remedy the unbalanced label
  problem, the label was used for the MAG network generation process. Indeed by
  setting the link-affinity probabilities as follows for the label, superior
  results were achieved:

  \[ \Theta_{label} = 
	\begin{pmatrix}
        0.95 & 0.25 \\
		0.25 & 0.95 \\
	\end{pmatrix}
	\] \\
  
  \noindent The resulting graph when considering the label is shown in figure
  \ref{fig:Moro_bias}.

  \begin{figure}[h]
		\centering
		\includegraphics[width=0.7\textwidth]{Moro_network_bias.png}
		\caption{Biased MAG graph of bank telemarketing dataset}
        \label{fig:Moro_bias}
  \end{figure}

  \noindent It now becomes apparent in figure \ref{fig:Moro_bias} that the
  nodes are almost perfectly separated from each other and grouped according to 
  their label. The GNN method GraphSage achieved an accuracy of over 95\% for 
  the graph shown in figure \ref{fig:Moro_bias}. This is of course a form of 
  cheating, as we cannot assume to know the labels of the entire graph and 
  especially when applying the model to new and unseen data which might not 
  contain any label information. It however shows, that if the graph provides 
  node clusters which corresponds to the node labels, that graph machine 
  learning can overcome the problem of unbalanced data to a cerain extent. 
  The difficulty for graph machine learning here is to find graph data including 
  features which naturally captures node clusters which correspond to the node 
  labels. For the synthetic graph generation setting using the MAG model, one 
  would have to collect data which generates clusters via the MAG model that 
  highly correlate with the label. An example for such a dataset was found and 
  while not perfect, it yielded good results and is presented in the following 
  section. 

  \subsection{Airline Passenger Satisfaction Survey}
  
  The US airline passenger satisfaction survey was a survey conducted in 2015
  by J.D. Power and the dataset was retrieved on the website Kaggle
  \citep{JDPower2015,KAGGLE2015}. This dataset revealed to be well suited for
  applying graph machine learning tasks via the MAG method. It further showed
  to be a competitive dataset for classic machine learning methods. Therefore,
  this dataset is suitable for a fair comparison of graph machine learning
  methods vs standard machine learning strategies. This dataset will be
  presented in more detail as it will be used for the detailed analyses which
  are to follow. \\

  \noindent An overview of the US Airline Passenger dataset is shown in table
  \ref{table:airline_summary}

  \newpage
  \begin{landscape}
  \pagestyle{empty}%
  \begin{table}[h]
    \centering
    \begin{tabular}{|l|l|c|c|}
      \hline
      \textbf{Variable} & \textbf{Description} & \textbf{Mean} & \textbf{Range} \\
      \hline
      Female & Gender of the passengers (Female, Male) & 0.5076 & 0 - 1 \\ 
      Disloyal Customer & Customer Type: The customer type (Loyal customer, disloyal customer) & 0.18 & 0 - 1 \\
      Age & Age: The actual age of the passengers & 39.101 & 7 - 85 \\
      Business Travel & Type of Travel: Purpose of the flight of the passengers (Personal Travel, Business Travel) & 0.6891 & 0 - 1 \\
      Class & Class: Travel class in the plane of the passengers (Business,
      Eco, Eco Plus) & - & 0 - 2 \\
      Flight Distance & Flight distance: The flight distance of this journey & 1'197.438 & 67 - 4'963 \\
      Departure Delay in Minutes & Departure Delay in Minutes: Minutes delayed when departure & 14.808 & 0 - 595 \\
      Satisfied & Satisfaction: Airline satisfaction level(Satisfaction, neutral or dissatisfaction) & 0.4295 & 0 - 1 \\
      Inflight wifi service & Satisfaction level of the inflight wifi service
      (0:Not Applicable;1-5) & - & 0 - 5 \\
      Ease of Online booking & Satisfaction level of online booking & - & 0 - 5
      \\
      Gate location & Satisfaction level of Gate location & - & 0 - 5 \\
      Food and drink & Satisfaction level of Food and drink & - & 0 - 5 \\
      Online boarding & Satisfaction level of online boarding & - & 0 - 5 \\
      Seat comfort & Satisfaction level of Seat comfort & - & 0 - 5 \\
      Inflight entertainment & Satisfaction level of inflight entertainment & -
                             & 0 - 5 \\
      On-board service & Satisfaction level of On-board service & - & 0 - 5 \\
      Leg room service & Satisfaction level of Leg room service & - & 0 - 5 \\
      Baggage handling & Satisfaction level of baggage handling & - & 0 - 5 \\
      Check-in service & Satisfaction level of Check-in service & - & 0 - 5 \\
      Inflight service & Satisfaction level of inflight service & - & 0 - 5 \\
      Cleanliness & Satisfaction level of Cleanliness & - & 0 - 5 \\
      \hline
    \end{tabular}
    \caption{Airline Dataset overview}
    \label{table:airline_summary}
  \end{table}
  \end{landscape}
  \newpage

  \noindent The dataset further included 14 variables 

  \subsection{Stochastic vs. Deterministic MAG}

  As addressed in section \ref{section:self_survey}, the question was raised 
  as to whether the MAG should form connections between observations
  stochastically or whether a deterministic setting yields better results. The 
  first insight gained when investigating this question lies in the fact that 
  the probability of two observations is generally very low. When setting the 
  threshold to 0.5, not a single connection between observations was made. This
  makes sense as the probability of a connection being formed decreases by
  design as the number of generation variables increases. This is implicitly
  shown in equation \ref{eq:MAG} where the product of probabilities is bound to
  decrease. For this reason, it is suggested to set $K=\rho\log_{2}N$
  for some constant $\rho$ \citep[p. 122]{kim2012multiplicative}. For the
  purpose of this thesis, the generation variables were selected such that
  $K\leqslant\log_{2} N$. The airline passenger satisfaction survey was used
  for a deterministic graph generation. The threshold probability for a
  connection was set to 0.2 in the MAG model. The resulting graph consisted of
  several disconnected sub-graphs which were for the most part clustered
  according to their group membership. Figure \ref{fig:det_MAG} shows the
  respective plots of the graph generation variables where the edge connections
  were removed. The sub-graphs are unfortunately small, however all graphs
  combined include all 6'000 nodes. The plots are meant to provide a high-level
  overview of the clusters in the sub-plots. 

  \begin{figure}[h]
		\centering
		\includegraphics[width=0.7\textwidth]{deterministic_MAG.png}
		\caption{Deterministic MAG graph}
        \label{fig:det_MAG}
  \end{figure}

  \noindent In short, the deterministic graph clustering creates disconnected 
  sub-graphs which forms clusters based on the nodes similarity to each other.
  In terms of performance, the performance and loss behavior of both the
  deterministically and stochastically generated graphs are virtually
  identical. This was true for the datasets considered for this thesis. For the 
  purpose of visualization the stochastically generated graph appears
  to be more useful, as one can identify the different cluster on a single
  connected graph. Further, the stochastic graph creates a nice social
  network that appear to be somewhat realistic given the homophily assumption
  and its corresponding link-affinity probabilities. For this reason, the
  stochastic graph generation process is kept. Nevertheless, deterministic
  graph generation appears to be useful if one wants to separate nodes in to
  more homogeneous sub-graphs. These sub-graphs or clusters could then be used
  for subsequent machine learning tasks with a cluster specific task. The
  clusters further could reveal information as to which clusters tend to be
  more or less satisfied. This is an area which could be interesting for future
  research. It is however not the focus of this thesis which is why it is not
  further investigated. 
  
