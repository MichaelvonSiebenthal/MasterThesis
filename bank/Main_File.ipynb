{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Script Bank Telemarketing Dataset\n",
    "\n",
    "First required packages and the data is loaded. Note that both the training- and validation dataset as well as the test dataset are taken from the bank-full.csv dataset. A random sampel of 6'000 nodes is taken for both subsets. \n",
    "\n",
    "If the dataset would be considered for the results chapter, the dataset would have first been randomly split into two datasets and then subsampled separately. The results do however not differ in any significant way. When sampling from the same dataset, technically identical observations could be present in both training and test dataset. Given the large size of the original datset with over 45'000 observations, this is unlikely to cause a problem or significantly bias the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "# import all required packages\n",
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank-full.csv',sep=';')\n",
    "df_train_valid = df.sample(n=6000,replace=False)\n",
    "df_feature_train = df_train_valid.copy(deep=True)\n",
    "# df_train_valid = pd.read_csv('bank.csv',sep=';')\n",
    "df_train_valid.reset_index(inplace=True,drop=True)\n",
    "df_test = df.sample(n=6000,replace=False)\n",
    "df_test.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the unbalanced label distribution for both datasets is shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     0.887\n",
       "yes    0.113\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_valid.y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     0.886667\n",
       "yes    0.113333\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>divorced</td>\n",
       "      <td>secondary</td>\n",
       "      <td>yes</td>\n",
       "      <td>339</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>23</td>\n",
       "      <td>may</td>\n",
       "      <td>496</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>91</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>18</td>\n",
       "      <td>may</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>375</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>20</td>\n",
       "      <td>aug</td>\n",
       "      <td>212</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1504</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>apr</td>\n",
       "      <td>131</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>269</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>25</td>\n",
       "      <td>aug</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>53</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>751</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>16</td>\n",
       "      <td>may</td>\n",
       "      <td>343</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>43</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>61</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>7</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>48</td>\n",
       "      <td>services</td>\n",
       "      <td>divorced</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>jun</td>\n",
       "      <td>428</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>60</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>2769</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>13</td>\n",
       "      <td>aug</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>40</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>3316</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>19</td>\n",
       "      <td>jun</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age          job   marital  education default  balance housing loan  \\\n",
       "0      33     services  divorced  secondary     yes      339     yes   no   \n",
       "1      37  blue-collar   married  secondary      no       91     yes   no   \n",
       "2      48   technician  divorced   tertiary      no      375      no   no   \n",
       "3      32  blue-collar   married    primary      no     1504     yes   no   \n",
       "4      55     services   married    primary      no      269      no   no   \n",
       "...   ...          ...       ...        ...     ...      ...     ...  ...   \n",
       "5995   53   technician  divorced  secondary      no      751     yes   no   \n",
       "5996   43  blue-collar   married    primary      no       61     yes   no   \n",
       "5997   48     services  divorced  secondary      no        0      no   no   \n",
       "5998   60    housemaid   married    unknown      no     2769      no   no   \n",
       "5999   40  blue-collar   married  secondary      no     3316      no   no   \n",
       "\n",
       "       contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0      unknown   23   may       496         4     -1         0  unknown  no  \n",
       "1     cellular   18   may         8         5     -1         0  unknown  no  \n",
       "2     cellular   20   aug       212         2     -1         0  unknown  no  \n",
       "3     cellular   17   apr       131         2     -1         0  unknown  no  \n",
       "4     cellular   25   aug        89         4     -1         0  unknown  no  \n",
       "...        ...  ...   ...       ...       ...    ...       ...      ...  ..  \n",
       "5995   unknown   16   may       343         4     -1         0  unknown  no  \n",
       "5996   unknown    7   may       261         1     -1         0  unknown  no  \n",
       "5997   unknown    5   jun       428         1     -1         0  unknown  no  \n",
       "5998  cellular   13   aug        96         2     -1         0  unknown  no  \n",
       "5999   unknown   19   jun       102         3     -1         0  unknown  no  \n",
       "\n",
       "[6000 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The variables are recoded into a useful format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_valid.age = df_train_valid.age.apply(lambda x: 0 if x < 25 else(1 if x < 35 else(2 if x < 50 else(3 if x < 65 else 4))))\n",
    "\n",
    "#df.job = df.job.apply(lambda x: 0 if x == 'unemployed' else(1 if x == 'services' \\\n",
    "#                            else(2 if x == 'management' else(3 if x == 'blue-collar' \\\n",
    "#                                else(4 if x == 'self-employed' else(5 if x == 'technician' \\\n",
    "#                                    else(6 if x == 'entrepreneur' else(7 if x == 'admin.' \\\n",
    "#                        else(8 if x =='student' else(9 if x == 'housemaid' \\\n",
    "#                            else(10 if x == 'retired' else 11)))))))))))\n",
    "\n",
    "#df.job = df.job.apply(lambda x: 0 if x == 'unemployed' or 'unknown' else(1 if x == 'services' \\\n",
    "#                        or x == 'management' or x == 'admin.' else(2 if x == 'blue-collar' or x == 'technician' \\\n",
    "#                                    or x == 'housemaid' else(3 if x == 'self-employed' or x == 'entrepreneur' \\\n",
    "#                                        else(4 if x == 'student' else 5)))))\n",
    "\n",
    "df_train_valid.job = df_train_valid.job.apply(lambda x: 0 if x == 'student' else(2 if x == 'retired' else(3 if x == 'unemployed' or x == 'unknown' else 1)))\n",
    "\n",
    "\n",
    "df_train_valid.marital = df_train_valid.marital.apply(lambda x: 0 if x == 'single' else(1 if x == 'married' else 2))\n",
    "\n",
    "df_train_valid.education = df_train_valid.education.apply(lambda x: 0 if x == 'primary' else(1 if x == 'secondary' else(2 if x == 'tertiary' else 3)))\n",
    "\n",
    "df_train_valid.default = df_train_valid.default.apply(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "df_train_valid.balance = df_train_valid.balance.apply(lambda x: 0 if x < 0 else(1 if x < 69. else(2 if x < 444. else(3 if x < 1480 else 4))))\n",
    "\n",
    "df_train_valid.housing = df_train_valid.housing.apply(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "df_train_valid.loan = df_train_valid.loan.apply(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "df_train_valid.contact = df_train_valid.contact.apply(lambda x: 0 if x == 'telephone' else(1 if x == 'cellular' else 2))\n",
    "\n",
    "#df_train_valid.duration = df_train_valid.duration.apply(lambda x: 0 if x < 104. else(1 if x < 185 else(2 if x < 329 else 3)))\n",
    "\n",
    "df_train_valid.pdays = df_train_valid.pdays.apply(lambda x: 1 if x > 150 or x == -1 else 0)\n",
    "\n",
    "df_train_valid.poutcome = df_train_valid.poutcome.apply(lambda x: 0 if x == 'failure' else(1 if x == 'success' else 2))\n",
    "\n",
    "df_train_valid.y = df_train_valid.y.apply(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "df_train_valid.drop(columns = ['day','month'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>496</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>212</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>343</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>428</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0       1    1        2          1        1        2        1     0        2   \n",
       "1       2    1        1          1        0        2        1     0        1   \n",
       "2       2    1        2          2        0        2        0     0        1   \n",
       "3       1    1        1          0        0        4        1     0        1   \n",
       "4       3    1        1          0        0        2        0     0        1   \n",
       "...   ...  ...      ...        ...      ...      ...      ...   ...      ...   \n",
       "5995    3    1        2          1        0        3        1     0        2   \n",
       "5996    2    1        1          0        0        1        1     0        2   \n",
       "5997    2    1        2          1        0        1        0     0        2   \n",
       "5998    3    1        1          3        0        4        0     0        1   \n",
       "5999    2    1        1          1        0        4        0     0        2   \n",
       "\n",
       "      duration  campaign  pdays  previous  poutcome  y  \n",
       "0          496         4      1         0         2  0  \n",
       "1            8         5      1         0         2  0  \n",
       "2          212         2      1         0         2  0  \n",
       "3          131         2      1         0         2  0  \n",
       "4           89         4      1         0         2  0  \n",
       "...        ...       ...    ...       ...       ... ..  \n",
       "5995       343         4      1         0         2  0  \n",
       "5996       261         1      1         0         2  0  \n",
       "5997       428         1      1         0         2  0  \n",
       "5998        96         2      1         0         2  0  \n",
       "5999       102         3      1         0         2  0  \n",
       "\n",
       "[6000 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Correlation Matrix of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.283918</td>\n",
       "      <td>0.386762</td>\n",
       "      <td>-0.103869</td>\n",
       "      <td>-0.023213</td>\n",
       "      <td>0.115639</td>\n",
       "      <td>-0.160765</td>\n",
       "      <td>-0.006281</td>\n",
       "      <td>-0.070751</td>\n",
       "      <td>-0.008487</td>\n",
       "      <td>0.014295</td>\n",
       "      <td>-0.022840</td>\n",
       "      <td>0.007707</td>\n",
       "      <td>-0.005489</td>\n",
       "      <td>0.005955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <td>0.283918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105888</td>\n",
       "      <td>-0.081616</td>\n",
       "      <td>0.019219</td>\n",
       "      <td>0.038378</td>\n",
       "      <td>-0.127784</td>\n",
       "      <td>-0.013694</td>\n",
       "      <td>-0.025929</td>\n",
       "      <td>0.056652</td>\n",
       "      <td>-0.015163</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>-0.027208</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.045540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital</th>\n",
       "      <td>0.386762</td>\n",
       "      <td>0.105888</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.125487</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>-0.022730</td>\n",
       "      <td>-0.000406</td>\n",
       "      <td>0.047586</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>-0.017519</td>\n",
       "      <td>0.013083</td>\n",
       "      <td>0.027424</td>\n",
       "      <td>-0.037055</td>\n",
       "      <td>0.016198</td>\n",
       "      <td>-0.060223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>-0.103869</td>\n",
       "      <td>-0.081616</td>\n",
       "      <td>-0.125487</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.021209</td>\n",
       "      <td>0.074360</td>\n",
       "      <td>-0.108899</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>-0.062673</td>\n",
       "      <td>-0.007047</td>\n",
       "      <td>0.009274</td>\n",
       "      <td>-0.062117</td>\n",
       "      <td>0.016715</td>\n",
       "      <td>-0.012005</td>\n",
       "      <td>0.065483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>-0.023213</td>\n",
       "      <td>0.019219</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>-0.021209</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.195727</td>\n",
       "      <td>0.007440</td>\n",
       "      <td>0.073329</td>\n",
       "      <td>0.030110</td>\n",
       "      <td>-0.005524</td>\n",
       "      <td>0.032290</td>\n",
       "      <td>0.026484</td>\n",
       "      <td>-0.026282</td>\n",
       "      <td>0.035632</td>\n",
       "      <td>-0.035669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.115639</td>\n",
       "      <td>0.038378</td>\n",
       "      <td>-0.022730</td>\n",
       "      <td>0.074360</td>\n",
       "      <td>-0.195727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083245</td>\n",
       "      <td>-0.129129</td>\n",
       "      <td>-0.054520</td>\n",
       "      <td>0.015353</td>\n",
       "      <td>-0.039818</td>\n",
       "      <td>-0.078568</td>\n",
       "      <td>0.054235</td>\n",
       "      <td>-0.050763</td>\n",
       "      <td>0.109420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>-0.160765</td>\n",
       "      <td>-0.127784</td>\n",
       "      <td>-0.000406</td>\n",
       "      <td>-0.108899</td>\n",
       "      <td>0.007440</td>\n",
       "      <td>-0.083245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053720</td>\n",
       "      <td>0.201726</td>\n",
       "      <td>-0.006183</td>\n",
       "      <td>-0.025600</td>\n",
       "      <td>0.085375</td>\n",
       "      <td>0.031337</td>\n",
       "      <td>-0.092456</td>\n",
       "      <td>-0.130790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan</th>\n",
       "      <td>-0.006281</td>\n",
       "      <td>-0.013694</td>\n",
       "      <td>0.047586</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>0.073329</td>\n",
       "      <td>-0.129129</td>\n",
       "      <td>0.053720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014926</td>\n",
       "      <td>-0.021321</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>0.024629</td>\n",
       "      <td>0.011195</td>\n",
       "      <td>-0.005005</td>\n",
       "      <td>-0.062869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contact</th>\n",
       "      <td>-0.070751</td>\n",
       "      <td>-0.025929</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>-0.062673</td>\n",
       "      <td>0.030110</td>\n",
       "      <td>-0.054520</td>\n",
       "      <td>0.201726</td>\n",
       "      <td>-0.014926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>-0.003880</td>\n",
       "      <td>0.130930</td>\n",
       "      <td>-0.172440</td>\n",
       "      <td>0.205053</td>\n",
       "      <td>-0.136755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>-0.008487</td>\n",
       "      <td>0.056652</td>\n",
       "      <td>-0.017519</td>\n",
       "      <td>-0.007047</td>\n",
       "      <td>-0.005524</td>\n",
       "      <td>0.015353</td>\n",
       "      <td>-0.006183</td>\n",
       "      <td>-0.021321</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.099943</td>\n",
       "      <td>-0.011869</td>\n",
       "      <td>0.015156</td>\n",
       "      <td>-0.010174</td>\n",
       "      <td>0.383809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign</th>\n",
       "      <td>0.014295</td>\n",
       "      <td>-0.015163</td>\n",
       "      <td>0.013083</td>\n",
       "      <td>0.009274</td>\n",
       "      <td>0.032290</td>\n",
       "      <td>-0.039818</td>\n",
       "      <td>-0.025600</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>-0.003880</td>\n",
       "      <td>-0.099943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066113</td>\n",
       "      <td>-0.029645</td>\n",
       "      <td>0.099411</td>\n",
       "      <td>-0.081280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pdays</th>\n",
       "      <td>-0.022840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>0.027424</td>\n",
       "      <td>-0.062117</td>\n",
       "      <td>0.026484</td>\n",
       "      <td>-0.078568</td>\n",
       "      <td>0.085375</td>\n",
       "      <td>0.024629</td>\n",
       "      <td>0.130930</td>\n",
       "      <td>-0.011869</td>\n",
       "      <td>0.066113</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.352838</td>\n",
       "      <td>0.359275</td>\n",
       "      <td>-0.152750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous</th>\n",
       "      <td>0.007707</td>\n",
       "      <td>-0.027208</td>\n",
       "      <td>-0.037055</td>\n",
       "      <td>0.016715</td>\n",
       "      <td>-0.026282</td>\n",
       "      <td>0.054235</td>\n",
       "      <td>0.031337</td>\n",
       "      <td>0.011195</td>\n",
       "      <td>-0.172440</td>\n",
       "      <td>0.015156</td>\n",
       "      <td>-0.029645</td>\n",
       "      <td>-0.352838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.463660</td>\n",
       "      <td>0.117577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poutcome</th>\n",
       "      <td>-0.005489</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.016198</td>\n",
       "      <td>-0.012005</td>\n",
       "      <td>0.035632</td>\n",
       "      <td>-0.050763</td>\n",
       "      <td>-0.092456</td>\n",
       "      <td>-0.005005</td>\n",
       "      <td>0.205053</td>\n",
       "      <td>-0.010174</td>\n",
       "      <td>0.099411</td>\n",
       "      <td>0.359275</td>\n",
       "      <td>-0.463660</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.096861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0.005955</td>\n",
       "      <td>0.045540</td>\n",
       "      <td>-0.060223</td>\n",
       "      <td>0.065483</td>\n",
       "      <td>-0.035669</td>\n",
       "      <td>0.109420</td>\n",
       "      <td>-0.130790</td>\n",
       "      <td>-0.062869</td>\n",
       "      <td>-0.136755</td>\n",
       "      <td>0.383809</td>\n",
       "      <td>-0.081280</td>\n",
       "      <td>-0.152750</td>\n",
       "      <td>0.117577</td>\n",
       "      <td>-0.096861</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age       job   marital  education   default   balance  \\\n",
       "age        1.000000  0.283918  0.386762  -0.103869 -0.023213  0.115639   \n",
       "job        0.283918  1.000000  0.105888  -0.081616  0.019219  0.038378   \n",
       "marital    0.386762  0.105888  1.000000  -0.125487  0.007292 -0.022730   \n",
       "education -0.103869 -0.081616 -0.125487   1.000000 -0.021209  0.074360   \n",
       "default   -0.023213  0.019219  0.007292  -0.021209  1.000000 -0.195727   \n",
       "balance    0.115639  0.038378 -0.022730   0.074360 -0.195727  1.000000   \n",
       "housing   -0.160765 -0.127784 -0.000406  -0.108899  0.007440 -0.083245   \n",
       "loan      -0.006281 -0.013694  0.047586  -0.054711  0.073329 -0.129129   \n",
       "contact   -0.070751 -0.025929  0.004065  -0.062673  0.030110 -0.054520   \n",
       "duration  -0.008487  0.056652 -0.017519  -0.007047 -0.005524  0.015353   \n",
       "campaign   0.014295 -0.015163  0.013083   0.009274  0.032290 -0.039818   \n",
       "pdays     -0.022840  0.003520  0.027424  -0.062117  0.026484 -0.078568   \n",
       "previous   0.007707 -0.027208 -0.037055   0.016715 -0.026282  0.054235   \n",
       "poutcome  -0.005489  0.007435  0.016198  -0.012005  0.035632 -0.050763   \n",
       "y          0.005955  0.045540 -0.060223   0.065483 -0.035669  0.109420   \n",
       "\n",
       "            housing      loan   contact  duration  campaign     pdays  \\\n",
       "age       -0.160765 -0.006281 -0.070751 -0.008487  0.014295 -0.022840   \n",
       "job       -0.127784 -0.013694 -0.025929  0.056652 -0.015163  0.003520   \n",
       "marital   -0.000406  0.047586  0.004065 -0.017519  0.013083  0.027424   \n",
       "education -0.108899 -0.054711 -0.062673 -0.007047  0.009274 -0.062117   \n",
       "default    0.007440  0.073329  0.030110 -0.005524  0.032290  0.026484   \n",
       "balance   -0.083245 -0.129129 -0.054520  0.015353 -0.039818 -0.078568   \n",
       "housing    1.000000  0.053720  0.201726 -0.006183 -0.025600  0.085375   \n",
       "loan       0.053720  1.000000 -0.014926 -0.021321  0.006043  0.024629   \n",
       "contact    0.201726 -0.014926  1.000000  0.003372 -0.003880  0.130930   \n",
       "duration  -0.006183 -0.021321  0.003372  1.000000 -0.099943 -0.011869   \n",
       "campaign  -0.025600  0.006043 -0.003880 -0.099943  1.000000  0.066113   \n",
       "pdays      0.085375  0.024629  0.130930 -0.011869  0.066113  1.000000   \n",
       "previous   0.031337  0.011195 -0.172440  0.015156 -0.029645 -0.352838   \n",
       "poutcome  -0.092456 -0.005005  0.205053 -0.010174  0.099411  0.359275   \n",
       "y         -0.130790 -0.062869 -0.136755  0.383809 -0.081280 -0.152750   \n",
       "\n",
       "           previous  poutcome         y  \n",
       "age        0.007707 -0.005489  0.005955  \n",
       "job       -0.027208  0.007435  0.045540  \n",
       "marital   -0.037055  0.016198 -0.060223  \n",
       "education  0.016715 -0.012005  0.065483  \n",
       "default   -0.026282  0.035632 -0.035669  \n",
       "balance    0.054235 -0.050763  0.109420  \n",
       "housing    0.031337 -0.092456 -0.130790  \n",
       "loan       0.011195 -0.005005 -0.062869  \n",
       "contact   -0.172440  0.205053 -0.136755  \n",
       "duration   0.015156 -0.010174  0.383809  \n",
       "campaign  -0.029645  0.099411 -0.081280  \n",
       "pdays     -0.352838  0.359275 -0.152750  \n",
       "previous   1.000000 -0.463660  0.117577  \n",
       "poutcome  -0.463660  1.000000 -0.096861  \n",
       "y          0.117577 -0.096861  1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df_train_valid.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration Attribute\n",
    "\n",
    "It is investigated, whether the attribute duration should be added as an attribute. This variable has the largest correlation with the label, which why it is considered as a partial substitute for the label. Using duration as an additional attribute unfortunately did not show to improve the classification accuracy. For that reason, the graph shown in the master's thesis including the results correspond to the graph which does not make use of the attribute duration. For simulation purposes, the duration attribute can easily be adding its link-affinity matrix to the link-affinity dictionary used in the MAG model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6000.000000\n",
       "mean      258.034667\n",
       "std       268.582431\n",
       "min         0.000000\n",
       "25%       100.000000\n",
       "50%       175.000000\n",
       "75%       318.000000\n",
       "max      3785.000000\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_valid.duration.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(df_train_valid.duration,bins=100)\n",
    "#plt.hist(df_train_valid.y,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_comparison = (df_train_valid.duration > 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "5995    False\n",
       "5996    False\n",
       "5997     True\n",
       "5998    False\n",
       "5999    False\n",
       "Name: duration, Length: 6000, dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_valid.y[value_comparison].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([690.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 361.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_train_valid.y[value_comparison==True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-15-fc427de996f3>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-fc427de996f3>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    genvars = df_train_valid[['age','job','marital','education','balance','housing']] # add y for biased graph\u001b[0m\n\u001b[0m                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "# below, the label y can be included to generate the biased graph\n",
    "genvars = df_train_valid[['age','job','marital','education','balance','housing']] # add y for biased graph\n",
    "#genvars = df_train_valid[['age','job','marital','education','balance','housing','duration']]\n",
    "genvars.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link-affinity matrices\n",
    "\n",
    "To create the biased graph, add the link-affinity matrix of the label to the affinity matrix dictionary. Further, the label must be added to the matrix containing the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age\n",
    "age_alpha0 = 0.90\n",
    "age_beta1 = 0.80\n",
    "age_beta2 = 0.60\n",
    "age_beta3 = 0.40\n",
    "age_beta4 = 0.20\n",
    "\n",
    "aff_age = np.array([[age_alpha0,age_beta1,age_beta2,age_beta3,age_beta4],\n",
    "                    [age_beta1,age_alpha0,age_beta1,age_beta2,age_beta3],\n",
    "                    [age_beta2,age_beta1,age_alpha0,age_beta1,age_beta2],\n",
    "                    [age_beta3,age_beta2,age_beta1,age_alpha0,age_beta1],\n",
    "                    [age_beta4,age_beta3,age_beta2,age_beta1,age_alpha0]])\n",
    "\n",
    "\n",
    "# job\n",
    "\n",
    "job_alpha0 = 0.90 # self\n",
    "job_beta_wf = 0.60 # workforce\n",
    "job_beta_nwf = 0.60 # not worforce\n",
    "\n",
    "#aff_job = np.array([[job_alpha0, job_beta_wf , job_beta_wf , job_beta_wf , job_beta_nwf, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_alpha0, job_beta_wf, job_beta_wf, job_beta_nwf, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_beta_wf, job_alpha0, job_beta_wf, job_beta_nwf, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_beta_wf, job_beta_wf, job_alpha0, job_beta_nwf, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_beta_wf, job_beta_wf, job_beta_wf, job_alpha0, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_beta_wf, job_beta_wf, job_beta_wf, job_beta_nwf, job_alpha0]])\n",
    "\n",
    "# employment\n",
    "emp_alpha0 = 0.90 # self\n",
    "emp_beta_wf = 0.75 # beta workforce / employed / unemployed vs student\n",
    "emp_beta_ret = 0.70 # beta retired vs workforce\n",
    "emp_beta_sr = 0.20 # gen gap student / retired\n",
    "\n",
    "aff_job = np.array([[emp_alpha0,emp_beta_wf,emp_beta_sr,emp_beta_wf],\n",
    "                    [emp_beta_wf,emp_alpha0,emp_beta_ret,emp_beta_wf],\n",
    "                    [emp_beta_sr,emp_beta_ret,emp_alpha0,emp_beta_ret],\n",
    "                    [emp_beta_wf,emp_beta_wf,emp_beta_ret,emp_alpha0]])\n",
    "\n",
    "\n",
    "# marital\n",
    "\n",
    "mar_alpha0 = 0.85\n",
    "mar_beta1 = 0.65\n",
    "\n",
    "aff_mar = np.array([[mar_alpha0, mar_beta1, mar_beta1],\n",
    "                    [mar_beta1, mar_alpha0, mar_beta1],\n",
    "                    [mar_beta1, mar_beta1, mar_alpha0]])\n",
    "\n",
    "# education\n",
    "edu_alpha0 = 0.85\n",
    "edu_beta1 = 0.70\n",
    "edu_beta2 = 0.55\n",
    "edu_beta3 = 0.40\n",
    "\n",
    "aff_edu = np.array([[edu_alpha0,edu_beta1,edu_beta2,edu_beta3],\n",
    "                    [edu_beta1,edu_alpha0,edu_beta1,edu_beta2],\n",
    "                    [edu_beta2,edu_beta1,edu_alpha0,edu_beta1],\n",
    "                    [edu_beta3,edu_beta2,edu_beta1,edu_alpha0]])\n",
    "\n",
    "\n",
    "# balance\n",
    "inc_alpha0 = 0.85\n",
    "inc_beta1 = 0.70\n",
    "inc_beta2 = 0.60\n",
    "inc_beta3 = 0.50\n",
    "inc_beta4 = 0.40\n",
    "inc_beta5 = 0.25\n",
    "\n",
    "aff_bal = np.array([[inc_alpha0,inc_beta1,inc_beta2,inc_beta3,inc_beta4],\n",
    "                    [inc_beta1,inc_alpha0,inc_beta1,inc_beta2,inc_beta3],\n",
    "                    [inc_beta2,inc_beta1,inc_alpha0,inc_beta1,inc_beta2],\n",
    "                    [inc_beta3,inc_beta2,inc_beta1,inc_alpha0,inc_beta1],\n",
    "                    [inc_beta4,inc_beta3,inc_beta2,inc_beta2,inc_alpha0]])\n",
    "\n",
    "# housing\n",
    "hous_alpha0 = 0.60\n",
    "hous_beta1 = 0.40\n",
    "\n",
    "aff_hous = np.array([[hous_alpha0,hous_beta1],\n",
    "                     [hous_beta1,hous_alpha0]])\n",
    "\n",
    "\n",
    "# duration\n",
    "dur_alpha0 = 0.70\n",
    "dur_alpha1 = 0.95\n",
    "dur_beta1 = 0.25\n",
    "\n",
    "aff_dur = np.array([[dur_alpha0,dur_beta1],\n",
    "                  [dur_beta1,dur_alpha1]])\n",
    "\n",
    "# outcome\n",
    "\n",
    "y_alpha1 = 0.95\n",
    "y_beta1 = 0.25\n",
    "\n",
    "aff_y = np.array([[y_alpha1,y_beta1],\n",
    "                  [y_beta1,y_alpha1]])\n",
    "\n",
    "aff = {}\n",
    "aff = {0:aff_age, 1:aff_job ,2:aff_mar ,3:aff_edu ,4:aff_bal ,5:aff_hous}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = genvars.to_numpy()\n",
    "x = x.astype(int)\n",
    "x = x.T\n",
    "\n",
    "P_u_v = np.empty((len(x.T),len(x.T)))\n",
    "prob_u_v = np.empty((len(x),1))\n",
    "u = np.empty((len(x),1))\n",
    "v = np.empty((len(x),1))\n",
    "\n",
    "# create probability for connection between u and v\n",
    "for i in range(len(x.T)):\n",
    "    u = x[:,i]\n",
    "\n",
    "    for k in range(len(x.T)):\n",
    "        v = x[:,k]\n",
    "\n",
    "        for j in range(len(x)):\n",
    "            aff_current = aff[j]\n",
    "            prob_u_v[j] = aff_current[u[j],v[j]]\n",
    "\n",
    "        P_u_v[i,k] = np.prod(prob_u_v) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.triu(P_u_v,1)\n",
    "\n",
    "for i in range(len(P_u_v)):\n",
    "    for j in range(len(P_u_v)):\n",
    "        if A[i,j] > np.random.rand():\n",
    "            A[i,j] = 1\n",
    "        else:\n",
    "            A[i,j] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A + A.T\n",
    "np.sum(A) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Plot the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_numpy_matrix(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.is_connected(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.draw(G,node_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.Series(df_train_valid.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_valid.drop(columns=['y'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_invest = features.index[features == 0].tolist()\n",
    "invest = features.index[features == 1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "nx.draw_networkx_nodes(G,pos,nodelist=not_invest,node_size=20,node_color='b',label='Did not Invest')\n",
    "nx.draw_networkx_nodes(G,pos,nodelist=invest,node_size=20,node_color='r',label='Did Invest')\n",
    "nx.draw_networkx_edges(G,pos)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data for GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_train.reset_index(inplace=True,drop=True)\n",
    "df_train_valid.age = df_feature_train.age\n",
    "df_train_valid.balance = df_feature_train.balance\n",
    "#df_train_valid.drop(columns = ['day','month'],inplace=True)\n",
    "df_train_valid.duration = df_feature_train.duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train_valid.drop(columns = ['pdays'],inplace=True)\n",
    "#df_train_valid.previous = df_feature_train.previous\n",
    "df_train_valid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return F.normalize(x, p=2, dim=-1)\n",
    "\n",
    "Norm = norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dgl data and assign features and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_dgl = dgl.from_networkx(G)\n",
    "feat = df_train_valid.copy(deep=True)\n",
    "#feat = pd.get_dummies(feat)\n",
    "scale = StandardScaler()\n",
    "feat = pd.DataFrame(scale.fit_transform(feat))\n",
    "\n",
    "G_dgl.ndata['feat'] =  torch.tensor(feat.values,dtype=torch.float)\n",
    "G_dgl.ndata['train_mask'] = torch.zeros(len(G_dgl.nodes()), dtype=torch.bool).bernoulli(0.8)\n",
    "G_dgl.ndata['label'] = torch.tensor(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_dgl.ndata['val_mask'] = torch.empty(len(G_dgl.nodes()))\n",
    "for i in range(len(G_dgl.ndata['train_mask'])):\n",
    "    if G_dgl.ndata['train_mask'][i] == True:\n",
    "        G_dgl.ndata['val_mask'][i] = False\n",
    "    else:\n",
    "        G_dgl.ndata['val_mask'][i] = True\n",
    "\n",
    "G_dgl.ndata['val_mask'] = G_dgl.ndata['val_mask'].type(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = G_dgl.ndata['feat']\n",
    "node_labels = G_dgl.ndata['label']\n",
    "train_mask = G_dgl.ndata['train_mask']\n",
    "valid_mask = G_dgl.ndata['val_mask']\n",
    "n_features = node_features.shape[1]\n",
    "n_labels = int(node_labels.max().item() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodes = (train_mask == True).nonzero(as_tuple=False)\n",
    "train_nids = torch.reshape(train_nodes,(-1,))\n",
    "valid_nodes = (valid_mask == True).nonzero(as_tuple=False)\n",
    "valid_nids = torch.reshape(valid_nodes,(-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataloaders for minibatch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 50\n",
    "#sampler = dgl.dataloading.MultiLayerNeighborSampler([4, 4, 4])\n",
    "sampler = dgl.dataloading.MultiLayerNeighborSampler([5, 10])\n",
    "#sampler = dgl.dataloading.MultiLayerNeighborSampler([None])\n",
    "train_dataloader = dgl.dataloading.NodeDataLoader(\n",
    "    G_dgl, train_nids, sampler,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(valid_nids)\n",
    "valid_dataloader = dgl.dataloading.NodeDataLoader(\n",
    "    G_dgl, valid_nids, sampler,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_nids))\n",
    "print(len(valid_nids))\n",
    "print(len(G.nodes()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define GraphSage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_feats, n_hidden, n_classes, n_layers,agg_type='pool'):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_classes = n_classes\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(dglnn.SAGEConv(in_feats, n_hidden, aggregator_type=agg_type, bias=True, feat_drop=0.02,norm=Norm,activation=nn.ReLU(inplace=False)))\n",
    "        for i in range(1, n_layers - 1):\n",
    "            self.layers.append(dglnn.SAGEConv(n_hidden, n_hidden, aggregator_type=agg_type, bias=True, feat_drop=0.02,norm=Norm,activation=nn.ReLU(inplace=False)))\n",
    "        self.layers.append(dglnn.SAGEConv(n_hidden, n_classes, aggregator_type=agg_type, bias=True, feat_drop=0.02,norm=None,activation=None))\n",
    "        \n",
    "    def forward(self, bipartites, x):\n",
    "        for l, (layer, bipartite) in enumerate(zip(self.layers, bipartites)):\n",
    "            x = layer(bipartite, x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GraphSage and get Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAGE(n_features, 124, n_labels, 2) #n_layers\n",
    "opt = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GraphSage\n",
    "best_accuracy = 0\n",
    "best_model_path = 'model.pt'\n",
    "epoch_losses_train = []\n",
    "plot_loss_valid = []\n",
    "train_acc = []\n",
    "valid_acc = []\n",
    "dur = []\n",
    "\n",
    "for epoch in range(400):\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    for step, (input_nodes, output_nodes, bipartites) in enumerate(train_dataloader):\n",
    "        inputs = node_features[input_nodes]\n",
    "        labels = node_labels[output_nodes]\n",
    "        logits = model(bipartites, inputs)\n",
    "        predictions = F.log_softmax(logits,dim=1)\n",
    "\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        loss_epoch += loss.detach().item()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        accuracy = accuracy_score(labels.numpy(), predictions.argmax(1).detach().numpy())\n",
    "        accuracy_epoch += accuracy\n",
    "    accuracy_epoch /= (step + 1)\n",
    "    loss_epoch /= (step + 1)\n",
    "    epoch_losses_train.append(loss_epoch)\n",
    "    train_acc.append(accuracy_epoch)\n",
    "    print('Epoch: {}, Training Accuracy: {:.3f}, Training Loss: {:.3f}'.format(epoch, accuracy_epoch, loss_epoch))\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for input_nodes, output_nodes, bipartites in valid_dataloader:\n",
    "            inputs = node_features[input_nodes]\n",
    "            labels.append(node_labels[output_nodes].numpy())\n",
    "            predictions.append(F.log_softmax(model(bipartites, inputs),dim=1).argmax(1).numpy())\n",
    "            valid_logits = model(bipartites, inputs)\n",
    "            valid_labels = node_labels[output_nodes]\n",
    "            valid_loss = F.cross_entropy(valid_logits, valid_labels)\n",
    "\n",
    "        predictions = np.concatenate(predictions)\n",
    "        labels = np.concatenate(labels)\n",
    "        \n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        dur.append(time.time() - t0)\n",
    "        print('Epoch: {}, Validation Accuracy: {:.3f}, Validation Loss: {:.3f}, Time: {:.4f}'.format(epoch, accuracy, valid_loss.item(), np.mean(dur)))\n",
    "        valid_acc.append(accuracy.item())\n",
    "        plot_loss_valid.append(valid_loss.item())\n",
    "    \n",
    "torch.save(model.state_dict(), best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(epoch_losses_train, label='Training Loss')\n",
    "plt.plot(plot_loss_valid, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(valid_acc, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "print('Classification Accuracy validation set {}'.format(accuracy_score(valid_labels,predictions)))\n",
    "print('-------------------------------------------------------------')\n",
    "print('Confusion Matrix validation set:')\n",
    "print(confusion_matrix(valid_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, plot_roc_curve\n",
    "\n",
    "roc_auc_score(valid_labels,predictions)\n",
    "#plot_roc_curve(logits, X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Machine Learning Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "f =  pd.get_dummies(features)\n",
    "#x = df.drop(columns='y')\n",
    "x_train, x_test, y_train, y_test = train_test_split(feat,f, test_size = 0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "x_train_tf = tf.convert_to_tensor(x_train)\n",
    "x_test_tf = tf.convert_to_tensor(x_test)\n",
    "y_train_tf = tf.convert_to_tensor(y_train)\n",
    "y_test_tf = tf.convert_to_tensor(y_test)\n",
    "\n",
    "model_ann = Sequential()\n",
    "\n",
    "model_ann.add(Dense(15, activation='relu'))\n",
    "#model_ann.add(Dense(8, activation='relu'))\n",
    "model_ann.add(Dense(2, activation='softmax'))\n",
    "#opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model_ann.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model_ann.fit(x_train_tf, y_train_tf,validation_data=(x_test_tf,y_test_tf), epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],label = 'Training Loss', color = 'blue')\n",
    "plt.plot(history.history['val_loss'],label = 'Validation Loss', color = 'red')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Binary Cross-Entropy Loss')\n",
    "plt.title('Loss per Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='validation accuracy')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_y = np.empty((len(features),1))\n",
    "\n",
    "for i in range(len(features)):\n",
    "    if features.iloc[i] == 1:\n",
    "        svm_y[i] = 1\n",
    "    else:\n",
    "        svm_y[i] = -1\n",
    "\n",
    "svm_y.astype(int)\n",
    "x_train, x_test, y_train, y_test = train_test_split(feat,svm_y, test_size = 0.6, shuffle=True)\n",
    "\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(x_train, y_train)\n",
    "print('Training Accuracy: ',clf.score(x_train, y_train))\n",
    "print('Validation Accuracy: ',clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=None, random_state=0)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "print('Training Accuracy: ',clf.score(x_train, y_train))\n",
    "print('Validation Accuracy: ',clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Generate the Test Graph and prepare Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.age = df_test.age.apply(lambda x: 0 if x < 25 else(1 if x < 35 else(2 if x < 50 else(3 if x < 65 else 4))))\n",
    "\n",
    "#df.job = df.job.apply(lambda x: 0 if x == 'unemployed' else(1 if x == 'services' \\\n",
    "#                            else(2 if x == 'management' else(3 if x == 'blue-collar' \\\n",
    "#                                else(4 if x == 'self-employed' else(5 if x == 'technician' \\\n",
    "#                                    else(6 if x == 'entrepreneur' else(7 if x == 'admin.' \\\n",
    "#                        else(8 if x =='student' else(9 if x == 'housemaid' \\\n",
    "#                            else(10 if x == 'retired' else 11)))))))))))\n",
    "\n",
    "#df.job = df.job.apply(lambda x: 0 if x == 'unemployed' or 'unknown' else(1 if x == 'services' \\\n",
    "#                        or x == 'management' or x == 'admin.' else(2 if x == 'blue-collar' or x == 'technician' \\\n",
    "#                                    or x == 'housemaid' else(3 if x == 'self-employed' or x == 'entrepreneur' \\\n",
    "#                                        else(4 if x == 'student' else 5)))))\n",
    "\n",
    "df_test.job = df_test.job.apply(lambda x: 0 if x == 'student' else(2 if x == 'retired' else(3 if x == 'unemployed' or x == 'unknown' else 1)))\n",
    "\n",
    "\n",
    "df_test.marital = df_test.marital.apply(lambda x: 0 if x == 'single' else(1 if x == 'married' else 2))\n",
    "\n",
    "df_test.education = df_test.education.apply(lambda x: 0 if x == 'primary' else(1 if x == 'secondary' else(2 if x == 'tertiary' else 3)))\n",
    "\n",
    "df_test.default = df_test.default.apply(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "df_test.balance = df_test.balance.apply(lambda x: 0 if x < 0 else(1 if x < 69. else(2 if x < 444. else(3 if x < 1480 else 4))))\n",
    "\n",
    "df_test.housing = df_test.housing.apply(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "df_test.loan = df_test.loan.apply(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "df_test.contact = df_test.contact.apply(lambda x: 0 if x == 'telephone' else(1 if x == 'cellular' else 2))\n",
    "\n",
    "df_test.duration = df_test.duration.apply(lambda x: 0 if x < 104. else(1 if x < 185 else(2 if x < 329 else 3)))\n",
    "\n",
    "df_test.pdays = df_test.pdays.apply(lambda x: 1 if x > 150 or x == -1 else 0)\n",
    "\n",
    "df_test.poutcome = df_test.poutcome.apply(lambda x: 0 if x == 'failure' else(1 if x == 'success' else 2))\n",
    "\n",
    "df_test.y = df_test.y.apply(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "df_test.drop(columns = ['day','month'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genvars = df_test[['age','job','marital','education','balance','housing']] # add y for biased graph\n",
    "genvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age\n",
    "age_alpha0 = 0.90\n",
    "age_beta1 = 0.80\n",
    "age_beta2 = 0.60\n",
    "age_beta3 = 0.40\n",
    "age_beta4 = 0.20\n",
    "\n",
    "aff_age = np.array([[age_alpha0,age_beta1,age_beta2,age_beta3,age_beta4],\n",
    "                    [age_beta1,age_alpha0,age_beta1,age_beta2,age_beta3],\n",
    "                    [age_beta2,age_beta1,age_alpha0,age_beta1,age_beta2],\n",
    "                    [age_beta3,age_beta2,age_beta1,age_alpha0,age_beta1],\n",
    "                    [age_beta4,age_beta3,age_beta2,age_beta1,age_alpha0]])\n",
    "\n",
    "\n",
    "# job\n",
    "\n",
    "job_alpha0 = 0.90 # self\n",
    "job_beta_wf = 0.60 # workforce\n",
    "job_beta_nwf = 0.60 # not worforce\n",
    "\n",
    "#aff_job = np.array([[job_alpha0, job_beta_wf , job_beta_wf , job_beta_wf , job_beta_nwf, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_alpha0, job_beta_wf, job_beta_wf, job_beta_nwf, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_beta_wf, job_alpha0, job_beta_wf, job_beta_nwf, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_beta_wf, job_beta_wf, job_alpha0, job_beta_nwf, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_beta_wf, job_beta_wf, job_beta_wf, job_alpha0, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_beta_wf, job_beta_wf, job_beta_wf, job_beta_nwf, job_alpha0]])\n",
    "\n",
    "# employment\n",
    "emp_alpha0 = 0.90 # self\n",
    "emp_beta_wf = 0.75 # beta workforce / employed / unemployed vs student\n",
    "emp_beta_ret = 0.70 # beta retired vs workforce\n",
    "emp_beta_sr = 0.20 # gen gap student / retired\n",
    "\n",
    "aff_job = np.array([[emp_alpha0,emp_beta_wf,emp_beta_sr,emp_beta_wf],\n",
    "                    [emp_beta_wf,emp_alpha0,emp_beta_ret,emp_beta_wf],\n",
    "                    [emp_beta_sr,emp_beta_ret,emp_alpha0,emp_beta_ret],\n",
    "                    [emp_beta_wf,emp_beta_wf,emp_beta_ret,emp_alpha0]])\n",
    "\n",
    "\n",
    "# marital\n",
    "\n",
    "mar_alpha0 = 0.85\n",
    "mar_beta1 = 0.65\n",
    "\n",
    "aff_mar = np.array([[mar_alpha0, mar_beta1, mar_beta1],\n",
    "                    [mar_beta1, mar_alpha0, mar_beta1],\n",
    "                    [mar_beta1, mar_beta1, mar_alpha0]])\n",
    "\n",
    "# education\n",
    "edu_alpha0 = 0.85\n",
    "edu_beta1 = 0.70\n",
    "edu_beta2 = 0.55\n",
    "edu_beta3 = 0.40\n",
    "\n",
    "aff_edu = np.array([[edu_alpha0,edu_beta1,edu_beta2,edu_beta3],\n",
    "                    [edu_beta1,edu_alpha0,edu_beta1,edu_beta2],\n",
    "                    [edu_beta2,edu_beta1,edu_alpha0,edu_beta1],\n",
    "                    [edu_beta3,edu_beta2,edu_beta1,edu_alpha0]])\n",
    "\n",
    "\n",
    "# balance\n",
    "inc_alpha0 = 0.85\n",
    "inc_beta1 = 0.70\n",
    "inc_beta2 = 0.60\n",
    "inc_beta3 = 0.50\n",
    "inc_beta4 = 0.40\n",
    "inc_beta5 = 0.25\n",
    "\n",
    "aff_bal = np.array([[inc_alpha0,inc_beta1,inc_beta2,inc_beta3,inc_beta4],\n",
    "                    [inc_beta1,inc_alpha0,inc_beta1,inc_beta2,inc_beta3],\n",
    "                    [inc_beta2,inc_beta1,inc_alpha0,inc_beta1,inc_beta2],\n",
    "                    [inc_beta3,inc_beta2,inc_beta1,inc_alpha0,inc_beta1],\n",
    "                    [inc_beta4,inc_beta3,inc_beta2,inc_beta2,inc_alpha0]])\n",
    "\n",
    "# housing\n",
    "hous_alpha0 = 0.60\n",
    "hous_beta1 = 0.40\n",
    "\n",
    "aff_hous = np.array([[hous_alpha0,hous_beta1],\n",
    "                     [hous_beta1,hous_alpha0]])\n",
    "\n",
    "# outcome\n",
    "\n",
    "y_alpha0 = 0.95\n",
    "y_beta1 = 0.25\n",
    "\n",
    "aff_y = np.array([[y_alpha0,y_beta1],\n",
    "                  [y_beta1,y_alpha0]])\n",
    "\n",
    "aff = {}\n",
    "aff = {0:aff_age, 1:aff_job ,2:aff_mar ,3:aff_edu ,4:aff_bal ,5:aff_hous}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = genvars.to_numpy()\n",
    "x = x.astype(int)\n",
    "x = x.T\n",
    "\n",
    "P_u_v = np.empty((len(x.T),len(x.T)))\n",
    "prob_u_v = np.empty((len(x),1))\n",
    "u = np.empty((len(x),1))\n",
    "v = np.empty((len(x),1))\n",
    "\n",
    "# create probability for connection between u and v\n",
    "for i in range(len(x.T)):\n",
    "    u = x[:,i]\n",
    "\n",
    "    for k in range(len(x.T)):\n",
    "        v = x[:,k]\n",
    "\n",
    "        for j in range(len(x)):\n",
    "            aff_current = aff[j]\n",
    "            prob_u_v[j] = aff_current[u[j],v[j]]\n",
    "\n",
    "        P_u_v[i,k] = np.prod(prob_u_v) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.triu(P_u_v,1)\n",
    "\n",
    "for i in range(len(P_u_v)):\n",
    "    for j in range(len(P_u_v)):\n",
    "        if A[i,j] > np.random.rand():\n",
    "            A[i,j] = 1\n",
    "        else:\n",
    "            A[i,j] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A + A.T\n",
    "np.sum(A) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_test = nx.from_numpy_matrix(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.Series(df_test.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Test Data to dgl Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_dgl_test = dgl.from_networkx(G_test)\n",
    "feat_test = df_test.drop(columns=['y'])\n",
    "#feat_test = pd.get_dummies(feat_test)\n",
    "scale = StandardScaler()\n",
    "feat_test = pd.DataFrame(scale.fit_transform(feat_test))\n",
    "\n",
    "embedding_test = torch.tensor(feat_test.values,dtype=torch.float)\n",
    "\n",
    "G_dgl_test.ndata['feat'] =  embedding_test\n",
    "#G_dgl.ndata['train_mask'] = torch.zeros(len(G_dgl.nodes()), dtype=torch.bool).bernoulli(0.2)\n",
    "G_dgl_test.ndata['label'] = torch.tensor(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = G_dgl_test.ndata['feat']\n",
    "node_labels = G_dgl_test.ndata['label']\n",
    "test_nids = G_dgl_test.nodes()\n",
    "n_features = node_features.shape[1]\n",
    "n_labels = int(node_labels.max().item() + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, graph, input_features, batch_size):\n",
    "    nodes = torch.arange(graph.number_of_nodes())\n",
    "    \n",
    "    sampler = dgl.dataloading.MultiLayerNeighborSampler([None])  # one layer at a time, taking all neighbors\n",
    "    dataloader = dgl.dataloading.NodeDataLoader(\n",
    "        graph, nodes, sampler,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for l, layer in enumerate(model.layers):\n",
    "            # Allocate a buffer of output representations for every node\n",
    "            # Note that the buffer is on CPU memory.\n",
    "            output_features = torch.zeros(\n",
    "                graph.number_of_nodes(), model.n_hidden if l != model.n_layers - 1 else model.n_classes)\n",
    "\n",
    "            for input_nodes, output_nodes, bipartites in tqdm.tqdm(dataloader):\n",
    "                bipartite = bipartites[0].to(torch.device('cpu'))\n",
    "\n",
    "                x = input_features[input_nodes]\n",
    "\n",
    "                # the following code is identical to the loop body in model.forward()\n",
    "                x = layer(bipartite, x)\n",
    "                if l != model.n_layers - 1:\n",
    "                    x = F.relu(x)\n",
    "                    \n",
    "                elif l == model.n_layers - 1:\n",
    "                    x = F.log_softmax(x,dim=1)\n",
    "\n",
    "                output_features[output_nodes] = x.cpu()\n",
    "            input_features = output_features\n",
    "    return output_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained GraphSage model parameters and get Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))\n",
    "all_predictions = inference(model, G_dgl_test, node_features, 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = all_predictions[test_nids].argmax(1)\n",
    "test_labels = node_labels[test_nids]\n",
    "test_accuracy = sklearn.metrics.accuracy_score(test_predictions.numpy(), test_labels.numpy())\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "print('Classification Accuracy test set {}'.format(accuracy_score(test_labels.numpy(),test_predictions.numpy())))\n",
    "print('-------------------------------------------------------------')\n",
    "print('Confusion Matrix test set:')\n",
    "print(confusion_matrix(test_labels.numpy(),test_predictions.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
