{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Script Bank Telemarketing Dataset\n",
    "\n",
    "First required packages and the data is loaded. Note that both the training- and validation dataset as well as the test dataset are taken from the bank-full.csv dataset. A random sampel of 6'000 nodes is taken for both subsets. \n",
    "\n",
    "If the dataset would be considered for the results chapter, the dataset would have first been randomly split into two datasets and then subsampled separately. The results do however not differ in any significant way. When sampling from the same dataset, technically identical observations could be present in both training and test dataset. Given the large size of the original datset with over 45'000 observations, this is unlikely to cause a problem or significantly bias the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use('ggplot')\n",
    "import networkx as nx\n",
    "\n",
    "df = pd.read_csv('bank-full.csv',sep=';')\n",
    "df_train_valid = df.sample(n=6000,replace=False)\n",
    "df_feature_train = df_train_valid.copy(deep=True)\n",
    "# df_train_valid = pd.read_csv('bank.csv',sep=';')\n",
    "df_train_valid.reset_index(inplace=True,drop=True)\n",
    "df_test = df.sample(n=6000,replace=False)\n",
    "df_test.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the unbalanced label distribution for both datasets is shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     0.8895\n",
       "yes    0.1105\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_valid.y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     0.8895\n",
       "yes    0.1105\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>875</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>apr</td>\n",
       "      <td>426</td>\n",
       "      <td>5</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>1245</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>9</td>\n",
       "      <td>may</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>services</td>\n",
       "      <td>divorced</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-179</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>jul</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>1687</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>aug</td>\n",
       "      <td>205</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>4695</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>29</td>\n",
       "      <td>aug</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>32</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>nov</td>\n",
       "      <td>231</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>32</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>367</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>276</td>\n",
       "      <td>3</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>59</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>11</td>\n",
       "      <td>jun</td>\n",
       "      <td>242</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>39</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>217</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>9</td>\n",
       "      <td>may</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>45</td>\n",
       "      <td>self-employed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>373</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>29</td>\n",
       "      <td>aug</td>\n",
       "      <td>82</td>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age            job   marital  education default  balance housing loan  \\\n",
       "0      42    blue-collar   married    primary      no      875     yes   no   \n",
       "1      40    blue-collar   married  secondary      no     1245     yes   no   \n",
       "2      45       services  divorced  secondary      no     -179      no   no   \n",
       "3      50       services   married  secondary      no     1687      no   no   \n",
       "4      51    blue-collar   married  secondary      no     4695      no   no   \n",
       "...   ...            ...       ...        ...     ...      ...     ...  ...   \n",
       "5995   32     technician   married   tertiary      no        0     yes   no   \n",
       "5996   32     technician   married  secondary      no      367     yes   no   \n",
       "5997   59         admin.   married    unknown      no        0      no   no   \n",
       "5998   39    blue-collar    single  secondary      no      217     yes   no   \n",
       "5999   45  self-employed   married    primary      no      373      no   no   \n",
       "\n",
       "       contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0     cellular   17   apr       426         5    148         1  failure  no  \n",
       "1      unknown    9   may       306         1     -1         0  unknown  no  \n",
       "2      unknown    3   jul       155         2     -1         0  unknown  no  \n",
       "3     cellular   19   aug       205         5     -1         0  unknown  no  \n",
       "4     cellular   29   aug         8        10     -1         0  unknown  no  \n",
       "...        ...  ...   ...       ...       ...    ...       ...      ...  ..  \n",
       "5995  cellular   19   nov       231         4     -1         0  unknown  no  \n",
       "5996  cellular   11   may       214         2    276         3  failure  no  \n",
       "5997   unknown   11   jun       242         2     -1         0  unknown  no  \n",
       "5998   unknown    9   may       107         1     -1         0  unknown  no  \n",
       "5999  cellular   29   aug        82        11     -1         0  unknown  no  \n",
       "\n",
       "[6000 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The variables are recoded into a useful format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_valid.age = df_train_valid.age.apply(lambda x: 0 if x < 25 else(1 if x < 35 else(2 if x < 50 else(3 if x < 65 else 4))))\n",
    "\n",
    "#df.job = df.job.apply(lambda x: 0 if x == 'unemployed' else(1 if x == 'services' \\\n",
    "#                            else(2 if x == 'management' else(3 if x == 'blue-collar' \\\n",
    "#                                else(4 if x == 'self-employed' else(5 if x == 'technician' \\\n",
    "#                                    else(6 if x == 'entrepreneur' else(7 if x == 'admin.' \\\n",
    "#                        else(8 if x =='student' else(9 if x == 'housemaid' \\\n",
    "#                            else(10 if x == 'retired' else 11)))))))))))\n",
    "\n",
    "#df.job = df.job.apply(lambda x: 0 if x == 'unemployed' or 'unknown' else(1 if x == 'services' \\\n",
    "#                        or x == 'management' or x == 'admin.' else(2 if x == 'blue-collar' or x == 'technician' \\\n",
    "#                                    or x == 'housemaid' else(3 if x == 'self-employed' or x == 'entrepreneur' \\\n",
    "#                                        else(4 if x == 'student' else 5)))))\n",
    "\n",
    "df_train_valid.job = df_train_valid.job.apply(lambda x: 0 if x == 'student' else(2 if x == 'retired' else(3 if x == 'unemployed' or x == 'unknown' else 1)))\n",
    "\n",
    "\n",
    "df_train_valid.marital = df_train_valid.marital.apply(lambda x: 0 if x == 'single' else(1 if x == 'married' else 2))\n",
    "\n",
    "df_train_valid.education = df_train_valid.education.apply(lambda x: 0 if x == 'primary' else(1 if x == 'secondary' else(2 if x == 'tertiary' else 3)))\n",
    "\n",
    "df_train_valid.default = df_train_valid.default.apply(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "df_train_valid.balance = df_train_valid.balance.apply(lambda x: 0 if x < 0 else(1 if x < 69. else(2 if x < 444. else(3 if x < 1480 else 4))))\n",
    "\n",
    "df_train_valid.housing = df_train_valid.housing.apply(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "df_train_valid.loan = df_train_valid.loan.apply(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "df_train_valid.contact = df_train_valid.contact.apply(lambda x: 0 if x == 'telephone' else(1 if x == 'cellular' else 2))\n",
    "\n",
    "#df_train_valid.duration = df_train_valid.duration.apply(lambda x: 0 if x < 104. else(1 if x < 185 else(2 if x < 329 else 3)))\n",
    "\n",
    "df_train_valid.pdays = df_train_valid.pdays.apply(lambda x: 1 if x > 150 or x == -1 else 0)\n",
    "\n",
    "df_train_valid.poutcome = df_train_valid.poutcome.apply(lambda x: 0 if x == 'failure' else(1 if x == 'success' else 2))\n",
    "\n",
    "df_train_valid.y = df_train_valid.y.apply(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "df_train_valid.drop(columns = ['day','month'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>426</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>205</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0       2    1        1          0        0        3        1     0        1   \n",
       "1       2    1        1          1        0        3        1     0        2   \n",
       "2       2    1        2          1        0        0        0     0        2   \n",
       "3       3    1        1          1        0        4        0     0        1   \n",
       "4       3    1        1          1        0        4        0     0        1   \n",
       "...   ...  ...      ...        ...      ...      ...      ...   ...      ...   \n",
       "5995    1    1        1          2        0        1        1     0        1   \n",
       "5996    1    1        1          1        0        2        1     0        1   \n",
       "5997    3    1        1          3        0        1        0     0        2   \n",
       "5998    2    1        0          1        0        2        1     0        2   \n",
       "5999    2    1        1          0        0        2        0     0        1   \n",
       "\n",
       "      duration  campaign  pdays  previous  poutcome  y  \n",
       "0          426         5      0         1         0  0  \n",
       "1          306         1      1         0         2  0  \n",
       "2          155         2      1         0         2  0  \n",
       "3          205         5      1         0         2  0  \n",
       "4            8        10      1         0         2  0  \n",
       "...        ...       ...    ...       ...       ... ..  \n",
       "5995       231         4      1         0         2  0  \n",
       "5996       214         2      1         3         0  0  \n",
       "5997       242         2      1         0         2  0  \n",
       "5998       107         1      1         0         2  0  \n",
       "5999        82        11      1         0         2  0  \n",
       "\n",
       "[6000 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Correlation Matrix of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.261981</td>\n",
       "      <td>0.383056</td>\n",
       "      <td>-0.087876</td>\n",
       "      <td>-0.056462</td>\n",
       "      <td>0.113596</td>\n",
       "      <td>-0.148238</td>\n",
       "      <td>-0.010577</td>\n",
       "      <td>-0.071989</td>\n",
       "      <td>0.015710</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.006671</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>-0.006399</td>\n",
       "      <td>0.033144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <td>0.261981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.122204</td>\n",
       "      <td>-0.073865</td>\n",
       "      <td>-0.013873</td>\n",
       "      <td>0.031039</td>\n",
       "      <td>-0.103607</td>\n",
       "      <td>-0.022565</td>\n",
       "      <td>-0.046115</td>\n",
       "      <td>0.033380</td>\n",
       "      <td>-0.031048</td>\n",
       "      <td>0.010488</td>\n",
       "      <td>-0.019466</td>\n",
       "      <td>0.014891</td>\n",
       "      <td>0.059850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital</th>\n",
       "      <td>0.383056</td>\n",
       "      <td>0.122204</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.099898</td>\n",
       "      <td>-0.009413</td>\n",
       "      <td>-0.018850</td>\n",
       "      <td>-0.004176</td>\n",
       "      <td>0.060802</td>\n",
       "      <td>0.021473</td>\n",
       "      <td>0.011351</td>\n",
       "      <td>-0.000679</td>\n",
       "      <td>0.037950</td>\n",
       "      <td>-0.026353</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>-0.036146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>-0.087876</td>\n",
       "      <td>-0.073865</td>\n",
       "      <td>-0.099898</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.037116</td>\n",
       "      <td>0.067563</td>\n",
       "      <td>-0.083177</td>\n",
       "      <td>-0.052810</td>\n",
       "      <td>-0.047082</td>\n",
       "      <td>-0.005049</td>\n",
       "      <td>0.009459</td>\n",
       "      <td>-0.058141</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>-0.026022</td>\n",
       "      <td>0.047759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>-0.056462</td>\n",
       "      <td>-0.013873</td>\n",
       "      <td>-0.009413</td>\n",
       "      <td>-0.037116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.196594</td>\n",
       "      <td>-0.011132</td>\n",
       "      <td>0.085998</td>\n",
       "      <td>0.047166</td>\n",
       "      <td>-0.012562</td>\n",
       "      <td>0.030132</td>\n",
       "      <td>0.025664</td>\n",
       "      <td>-0.025640</td>\n",
       "      <td>0.035317</td>\n",
       "      <td>-0.022462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.113596</td>\n",
       "      <td>0.031039</td>\n",
       "      <td>-0.018850</td>\n",
       "      <td>0.067563</td>\n",
       "      <td>-0.196594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.077403</td>\n",
       "      <td>-0.143608</td>\n",
       "      <td>-0.073144</td>\n",
       "      <td>0.068902</td>\n",
       "      <td>-0.034457</td>\n",
       "      <td>-0.086636</td>\n",
       "      <td>0.050150</td>\n",
       "      <td>-0.053254</td>\n",
       "      <td>0.130707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>-0.148238</td>\n",
       "      <td>-0.103607</td>\n",
       "      <td>-0.004176</td>\n",
       "      <td>-0.083177</td>\n",
       "      <td>-0.011132</td>\n",
       "      <td>-0.077403</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054810</td>\n",
       "      <td>0.205339</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>-0.013720</td>\n",
       "      <td>0.075983</td>\n",
       "      <td>0.052443</td>\n",
       "      <td>-0.078078</td>\n",
       "      <td>-0.124079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan</th>\n",
       "      <td>-0.010577</td>\n",
       "      <td>-0.022565</td>\n",
       "      <td>0.060802</td>\n",
       "      <td>-0.052810</td>\n",
       "      <td>0.085998</td>\n",
       "      <td>-0.143608</td>\n",
       "      <td>0.054810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009429</td>\n",
       "      <td>-0.005583</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.024506</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>-0.071414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contact</th>\n",
       "      <td>-0.071989</td>\n",
       "      <td>-0.046115</td>\n",
       "      <td>0.021473</td>\n",
       "      <td>-0.047082</td>\n",
       "      <td>0.047166</td>\n",
       "      <td>-0.073144</td>\n",
       "      <td>0.205339</td>\n",
       "      <td>-0.009429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003202</td>\n",
       "      <td>-0.011089</td>\n",
       "      <td>0.121095</td>\n",
       "      <td>-0.155997</td>\n",
       "      <td>0.206005</td>\n",
       "      <td>-0.125987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>0.015710</td>\n",
       "      <td>0.033380</td>\n",
       "      <td>0.011351</td>\n",
       "      <td>-0.005049</td>\n",
       "      <td>-0.012562</td>\n",
       "      <td>0.068902</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>-0.005583</td>\n",
       "      <td>-0.003202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.098502</td>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.031320</td>\n",
       "      <td>0.015299</td>\n",
       "      <td>0.405387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign</th>\n",
       "      <td>0.001175</td>\n",
       "      <td>-0.031048</td>\n",
       "      <td>-0.000679</td>\n",
       "      <td>0.009459</td>\n",
       "      <td>0.030132</td>\n",
       "      <td>-0.034457</td>\n",
       "      <td>-0.013720</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>-0.011089</td>\n",
       "      <td>-0.098502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058064</td>\n",
       "      <td>-0.021724</td>\n",
       "      <td>0.095448</td>\n",
       "      <td>-0.076564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pdays</th>\n",
       "      <td>0.006671</td>\n",
       "      <td>0.010488</td>\n",
       "      <td>0.037950</td>\n",
       "      <td>-0.058141</td>\n",
       "      <td>0.025664</td>\n",
       "      <td>-0.086636</td>\n",
       "      <td>0.075983</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.121095</td>\n",
       "      <td>-0.009505</td>\n",
       "      <td>0.058064</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.316601</td>\n",
       "      <td>0.344404</td>\n",
       "      <td>-0.146227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous</th>\n",
       "      <td>0.004059</td>\n",
       "      <td>-0.019466</td>\n",
       "      <td>-0.026353</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>-0.025640</td>\n",
       "      <td>0.050150</td>\n",
       "      <td>0.052443</td>\n",
       "      <td>0.024506</td>\n",
       "      <td>-0.155997</td>\n",
       "      <td>-0.031320</td>\n",
       "      <td>-0.021724</td>\n",
       "      <td>-0.316601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.465801</td>\n",
       "      <td>0.080132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poutcome</th>\n",
       "      <td>-0.006399</td>\n",
       "      <td>0.014891</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>-0.026022</td>\n",
       "      <td>0.035317</td>\n",
       "      <td>-0.053254</td>\n",
       "      <td>-0.078078</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>0.206005</td>\n",
       "      <td>0.015299</td>\n",
       "      <td>0.095448</td>\n",
       "      <td>0.344404</td>\n",
       "      <td>-0.465801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.078754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0.033144</td>\n",
       "      <td>0.059850</td>\n",
       "      <td>-0.036146</td>\n",
       "      <td>0.047759</td>\n",
       "      <td>-0.022462</td>\n",
       "      <td>0.130707</td>\n",
       "      <td>-0.124079</td>\n",
       "      <td>-0.071414</td>\n",
       "      <td>-0.125987</td>\n",
       "      <td>0.405387</td>\n",
       "      <td>-0.076564</td>\n",
       "      <td>-0.146227</td>\n",
       "      <td>0.080132</td>\n",
       "      <td>-0.078754</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age       job   marital  education   default   balance  \\\n",
       "age        1.000000  0.261981  0.383056  -0.087876 -0.056462  0.113596   \n",
       "job        0.261981  1.000000  0.122204  -0.073865 -0.013873  0.031039   \n",
       "marital    0.383056  0.122204  1.000000  -0.099898 -0.009413 -0.018850   \n",
       "education -0.087876 -0.073865 -0.099898   1.000000 -0.037116  0.067563   \n",
       "default   -0.056462 -0.013873 -0.009413  -0.037116  1.000000 -0.196594   \n",
       "balance    0.113596  0.031039 -0.018850   0.067563 -0.196594  1.000000   \n",
       "housing   -0.148238 -0.103607 -0.004176  -0.083177 -0.011132 -0.077403   \n",
       "loan      -0.010577 -0.022565  0.060802  -0.052810  0.085998 -0.143608   \n",
       "contact   -0.071989 -0.046115  0.021473  -0.047082  0.047166 -0.073144   \n",
       "duration   0.015710  0.033380  0.011351  -0.005049 -0.012562  0.068902   \n",
       "campaign   0.001175 -0.031048 -0.000679   0.009459  0.030132 -0.034457   \n",
       "pdays      0.006671  0.010488  0.037950  -0.058141  0.025664 -0.086636   \n",
       "previous   0.004059 -0.019466 -0.026353   0.009824 -0.025640  0.050150   \n",
       "poutcome  -0.006399  0.014891  0.015504  -0.026022  0.035317 -0.053254   \n",
       "y          0.033144  0.059850 -0.036146   0.047759 -0.022462  0.130707   \n",
       "\n",
       "            housing      loan   contact  duration  campaign     pdays  \\\n",
       "age       -0.148238 -0.010577 -0.071989  0.015710  0.001175  0.006671   \n",
       "job       -0.103607 -0.022565 -0.046115  0.033380 -0.031048  0.010488   \n",
       "marital   -0.004176  0.060802  0.021473  0.011351 -0.000679  0.037950   \n",
       "education -0.083177 -0.052810 -0.047082 -0.005049  0.009459 -0.058141   \n",
       "default   -0.011132  0.085998  0.047166 -0.012562  0.030132  0.025664   \n",
       "balance   -0.077403 -0.143608 -0.073144  0.068902 -0.034457 -0.086636   \n",
       "housing    1.000000  0.054810  0.205339  0.004543 -0.013720  0.075983   \n",
       "loan       0.054810  1.000000 -0.009429 -0.005583  0.006918  0.011091   \n",
       "contact    0.205339 -0.009429  1.000000 -0.003202 -0.011089  0.121095   \n",
       "duration   0.004543 -0.005583 -0.003202  1.000000 -0.098502 -0.009505   \n",
       "campaign  -0.013720  0.006918 -0.011089 -0.098502  1.000000  0.058064   \n",
       "pdays      0.075983  0.011091  0.121095 -0.009505  0.058064  1.000000   \n",
       "previous   0.052443  0.024506 -0.155997 -0.031320 -0.021724 -0.316601   \n",
       "poutcome  -0.078078  0.010827  0.206005  0.015299  0.095448  0.344404   \n",
       "y         -0.124079 -0.071414 -0.125987  0.405387 -0.076564 -0.146227   \n",
       "\n",
       "           previous  poutcome         y  \n",
       "age        0.004059 -0.006399  0.033144  \n",
       "job       -0.019466  0.014891  0.059850  \n",
       "marital   -0.026353  0.015504 -0.036146  \n",
       "education  0.009824 -0.026022  0.047759  \n",
       "default   -0.025640  0.035317 -0.022462  \n",
       "balance    0.050150 -0.053254  0.130707  \n",
       "housing    0.052443 -0.078078 -0.124079  \n",
       "loan       0.024506  0.010827 -0.071414  \n",
       "contact   -0.155997  0.206005 -0.125987  \n",
       "duration  -0.031320  0.015299  0.405387  \n",
       "campaign  -0.021724  0.095448 -0.076564  \n",
       "pdays     -0.316601  0.344404 -0.146227  \n",
       "previous   1.000000 -0.465801  0.080132  \n",
       "poutcome  -0.465801  1.000000 -0.078754  \n",
       "y          0.080132 -0.078754  1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df_train_valid.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration Attribute\n",
    "\n",
    "It is investigated, whether the attribute duration should be added as an attribute. This variable has the largest correlation with the label, which why it is considered as a partial substitute for the label. Using duration as an additional attribute unfortunately did not show to improve the classification accuracy. For that reason, the graph shown in the master's thesis including the results correspond to the graph which does not make use of the attribute duration. For simulation purposes, the duration attribute can easily be adding its link-affinity matrix to the link-affinity dictionary used in the MAG model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6000.000000\n",
       "mean      257.196500\n",
       "std       255.730268\n",
       "min         3.000000\n",
       "25%       101.000000\n",
       "50%       179.000000\n",
       "75%       319.000000\n",
       "max      3102.000000\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_valid.duration.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(df_train_valid.duration,bins=100)\n",
    "#plt.hist(df_train_valid.y,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_comparison = (df_train_valid.duration > 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "5995    False\n",
       "5996    False\n",
       "5997    False\n",
       "5998    False\n",
       "5999    False\n",
       "Name: duration, Length: 6000, dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_valid.y[value_comparison].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([676.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 370.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_train_valid.y[value_comparison==True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.883667</td>\n",
       "      <td>1.105833</td>\n",
       "      <td>0.824667</td>\n",
       "      <td>1.209333</td>\n",
       "      <td>2.408833</td>\n",
       "      <td>0.565167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.804098</td>\n",
       "      <td>0.460436</td>\n",
       "      <td>0.599431</td>\n",
       "      <td>0.759348</td>\n",
       "      <td>1.252577</td>\n",
       "      <td>0.495776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          job      marital    education      balance  \\\n",
       "count  6000.000000  6000.000000  6000.000000  6000.000000  6000.000000   \n",
       "mean      1.883667     1.105833     0.824667     1.209333     2.408833   \n",
       "std       0.804098     0.460436     0.599431     0.759348     1.252577   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     1.000000     0.000000     1.000000     1.000000   \n",
       "50%       2.000000     1.000000     1.000000     1.000000     3.000000   \n",
       "75%       2.000000     1.000000     1.000000     2.000000     3.000000   \n",
       "max       4.000000     3.000000     2.000000     3.000000     4.000000   \n",
       "\n",
       "           housing  \n",
       "count  6000.000000  \n",
       "mean      0.565167  \n",
       "std       0.495776  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#genvars = df_train_valid.drop(columns=['pdays','campaign','poutcome','previous','contact','loan','default','y'])\n",
    "genvars = df_train_valid[['age','job','marital','education','balance','housing']]\n",
    "#genvars = df_train_valid[['age','job','marital','education','balance','housing','duration']]\n",
    "genvars.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link-affinity matrices\n",
    "\n",
    "To create the biased graph, add the link-affinity matrix of the label to the affinity matrix dictionary. Further, the label must be added to the matrix containing the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age\n",
    "age_alpha0 = 0.90\n",
    "age_beta1 = 0.80\n",
    "age_beta2 = 0.60\n",
    "age_beta3 = 0.40\n",
    "age_beta4 = 0.20\n",
    "\n",
    "aff_age = np.array([[age_alpha0,age_beta1,age_beta2,age_beta3,age_beta4],\n",
    "                    [age_beta1,age_alpha0,age_beta1,age_beta2,age_beta3],\n",
    "                    [age_beta2,age_beta1,age_alpha0,age_beta1,age_beta2],\n",
    "                    [age_beta3,age_beta2,age_beta1,age_alpha0,age_beta1],\n",
    "                    [age_beta4,age_beta3,age_beta2,age_beta1,age_alpha0]])\n",
    "\n",
    "\n",
    "# job\n",
    "\n",
    "job_alpha0 = 0.90 # self\n",
    "job_beta_wf = 0.60 # workforce\n",
    "job_beta_nwf = 0.60 # not worforce\n",
    "\n",
    "#aff_job = np.array([[job_alpha0, job_beta_wf , job_beta_wf , job_beta_wf , job_beta_nwf, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_alpha0, job_beta_wf, job_beta_wf, job_beta_nwf, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_beta_wf, job_alpha0, job_beta_wf, job_beta_nwf, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_beta_wf, job_beta_wf, job_alpha0, job_beta_nwf, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_beta_wf, job_beta_wf, job_beta_wf, job_alpha0, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_beta_wf, job_beta_wf, job_beta_wf, job_beta_nwf, job_alpha0]])\n",
    "\n",
    "# employment\n",
    "emp_alpha0 = 0.90 # self\n",
    "emp_beta_wf = 0.75 # beta workforce / employed / unemployed vs student\n",
    "emp_beta_ret = 0.70 # beta retired vs workforce\n",
    "emp_beta_sr = 0.20 # gen gap student / retired\n",
    "\n",
    "aff_job = np.array([[emp_alpha0,emp_beta_wf,emp_beta_sr,emp_beta_wf],\n",
    "                    [emp_beta_wf,emp_alpha0,emp_beta_ret,emp_beta_wf],\n",
    "                    [emp_beta_sr,emp_beta_ret,emp_alpha0,emp_beta_ret],\n",
    "                    [emp_beta_wf,emp_beta_wf,emp_beta_ret,emp_alpha0]])\n",
    "\n",
    "\n",
    "# marital\n",
    "\n",
    "mar_alpha0 = 0.85\n",
    "mar_beta1 = 0.65\n",
    "\n",
    "aff_mar = np.array([[mar_alpha0, mar_beta1, mar_beta1],\n",
    "                    [mar_beta1, mar_alpha0, mar_beta1],\n",
    "                    [mar_beta1, mar_beta1, mar_alpha0]])\n",
    "\n",
    "# education\n",
    "edu_alpha0 = 0.85\n",
    "edu_beta1 = 0.70\n",
    "edu_beta2 = 0.55\n",
    "edu_beta3 = 0.40\n",
    "\n",
    "aff_edu = np.array([[edu_alpha0,edu_beta1,edu_beta2,edu_beta3],\n",
    "                    [edu_beta1,edu_alpha0,edu_beta1,edu_beta2],\n",
    "                    [edu_beta2,edu_beta1,edu_alpha0,edu_beta1],\n",
    "                    [edu_beta3,edu_beta2,edu_beta1,edu_alpha0]])\n",
    "\n",
    "\n",
    "# balance\n",
    "inc_alpha0 = 0.85\n",
    "inc_beta1 = 0.70\n",
    "inc_beta2 = 0.60\n",
    "inc_beta3 = 0.50\n",
    "inc_beta4 = 0.40\n",
    "inc_beta5 = 0.25\n",
    "\n",
    "aff_bal = np.array([[inc_alpha0,inc_beta1,inc_beta2,inc_beta3,inc_beta4],\n",
    "                    [inc_beta1,inc_alpha0,inc_beta1,inc_beta2,inc_beta3],\n",
    "                    [inc_beta2,inc_beta1,inc_alpha0,inc_beta1,inc_beta2],\n",
    "                    [inc_beta3,inc_beta2,inc_beta1,inc_alpha0,inc_beta1],\n",
    "                    [inc_beta4,inc_beta3,inc_beta2,inc_beta2,inc_alpha0]])\n",
    "\n",
    "# housing\n",
    "hous_alpha0 = 0.60\n",
    "hous_beta1 = 0.40\n",
    "\n",
    "aff_hous = np.array([[hous_alpha0,hous_beta1],\n",
    "                     [hous_beta1,hous_alpha0]])\n",
    "\n",
    "\n",
    "# duration\n",
    "dur_alpha0 = 0.70\n",
    "dur_alpha1 = 0.95\n",
    "dur_beta1 = 0.25\n",
    "\n",
    "aff_dur = np.array([[dur_alpha0,dur_beta1],\n",
    "                  [dur_beta1,dur_alpha1]])\n",
    "\n",
    "# outcome\n",
    "\n",
    "y_alpha1 = 0.95\n",
    "y_beta1 = 0.25\n",
    "\n",
    "aff_y = np.array([[y_alpha1,y_beta1],\n",
    "                  [y_beta1,y_alpha1]])\n",
    "\n",
    "aff = {}\n",
    "aff = {0:aff_age, 1:aff_job ,2:aff_mar ,3:aff_edu ,4:aff_bal ,5:aff_hous}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = genvars.to_numpy()\n",
    "x = x.astype(int)\n",
    "x = x.T\n",
    "\n",
    "P_u_v = np.empty((len(x.T),len(x.T)))\n",
    "prob_u_v = np.empty((len(x),1))\n",
    "u = np.empty((len(x),1))\n",
    "v = np.empty((len(x),1))\n",
    "\n",
    "# create probability for connection between u and v\n",
    "for i in range(len(x.T)):\n",
    "    u = x[:,i]\n",
    "\n",
    "    for k in range(len(x.T)):\n",
    "        v = x[:,k]\n",
    "\n",
    "        for j in range(len(x)):\n",
    "            aff_current = aff[j]\n",
    "            prob_u_v[j] = aff_current[u[j],v[j]]\n",
    "\n",
    "        P_u_v[i,k] = np.prod(prob_u_v) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.triu(P_u_v,1)\n",
    "\n",
    "for i in range(len(P_u_v)):\n",
    "    for j in range(len(P_u_v)):\n",
    "        if A[i,j] > np.random.rand():\n",
    "            A[i,j] = 1\n",
    "        else:\n",
    "            A[i,j] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A + A.T\n",
    "np.sum(A) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Plot the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_numpy_matrix(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.is_connected(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.draw(G,node_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.Series(df_train_valid.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_valid.drop(columns=['y'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_invest = features.index[features == 0].tolist()\n",
    "invest = features.index[features == 1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G,pos,nodelist=not_invest,node_size=20,node_color='b',label='Did not Invest')\n",
    "nx.draw(G,pos,nodelist=invest,node_size=20,node_color='r',label='Did Invest')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data for GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_train.reset_index(inplace=True,drop=True)\n",
    "df_train_valid.age = df_feature_train.age\n",
    "df_train_valid.balance = df_feature_train.balance\n",
    "#df_train_valid.drop(columns = ['day','month'],inplace=True)\n",
    "df_train_valid.duration = df_feature_train.duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train_valid.drop(columns = ['pdays'],inplace=True)\n",
    "#df_train_valid.previous = df_feature_train.previous\n",
    "df_train_valid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required packages\n",
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from sage import SAGEConv\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return F.normalize(x, p=2, dim=-1)\n",
    "\n",
    "Norm = norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dgl data and assign features and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "G_dgl = dgl.from_networkx(G)\n",
    "feat = df_train_valid.copy(deep=True)\n",
    "#feat = pd.get_dummies(feat[['job','marital']])\n",
    "scale = StandardScaler()\n",
    "feat = pd.DataFrame(scale.fit_transform(feat))\n",
    "\n",
    "embedding = torch.tensor(feat.values,dtype=torch.float)\n",
    "\n",
    "G_dgl.ndata['feat'] =  embedding\n",
    "G_dgl.ndata['train_mask'] = torch.zeros(len(G_dgl.nodes()), dtype=torch.bool).bernoulli(0.8)\n",
    "G_dgl.ndata['label'] = torch.tensor(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_dgl.ndata['val_mask'] = torch.empty(len(G_dgl.nodes()))\n",
    "for i in range(len(G_dgl.ndata['train_mask'])):\n",
    "    if G_dgl.ndata['train_mask'][i] == True:\n",
    "        G_dgl.ndata['val_mask'][i] = False\n",
    "    else:\n",
    "        G_dgl.ndata['val_mask'][i] = True\n",
    "\n",
    "G_dgl.ndata['val_mask'] = G_dgl.ndata['val_mask'].type(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = G_dgl.ndata['feat']\n",
    "node_labels = G_dgl.ndata['label']\n",
    "train_mask = G_dgl.ndata['train_mask']\n",
    "valid_mask = G_dgl.ndata['val_mask']\n",
    "n_features = node_features.shape[1]\n",
    "n_labels = int(node_labels.max().item() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodes = (train_mask == True).nonzero(as_tuple=False)\n",
    "train_nids = torch.reshape(train_nodes,(-1,))\n",
    "valid_nodes = (valid_mask == True).nonzero(as_tuple=False)\n",
    "valid_nids = torch.reshape(valid_nodes,(-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataloaders for minibatch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "#sampler = dgl.dataloading.MultiLayerNeighborSampler([4, 4, 4])\n",
    "sampler = dgl.dataloading.MultiLayerNeighborSampler([5, 10])\n",
    "#sampler = dgl.dataloading.MultiLayerNeighborSampler([None])\n",
    "train_dataloader = dgl.dataloading.NodeDataLoader(\n",
    "    G_dgl, train_nids, sampler,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(valid_nids)\n",
    "valid_dataloader = dgl.dataloading.NodeDataLoader(\n",
    "    G_dgl, valid_nids, sampler,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_nids))\n",
    "print(len(valid_nids))\n",
    "print(len(G.nodes()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define GraphSage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import sklearn.metrics\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_feats, n_hidden, n_classes, n_layers,agg_type='pool'):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_classes = n_classes\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(dglnn.SAGEConv(in_feats, n_hidden, aggregator_type=agg_type, bias=True, feat_drop=0.02,norm=Norm,activation=nn.ReLU(inplace=False)))\n",
    "        for i in range(1, n_layers - 1):\n",
    "            self.layers.append(dglnn.SAGEConv(n_hidden, n_hidden, aggregator_type=agg_type, bias=True, feat_drop=0.02,norm=Norm,activation=nn.ReLU(inplace=False)))\n",
    "        self.layers.append(dglnn.SAGEConv(n_hidden, n_classes, aggregator_type=agg_type, bias=True, feat_drop=0.02,norm=Norm,activation=None))\n",
    "        \n",
    "    def forward(self, bipartites, x):\n",
    "        for l, (layer, bipartite) in enumerate(zip(self.layers, bipartites)):\n",
    "            x = layer(bipartite, x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GraphSage and get Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAGE(n_features, len(feat), n_labels, 2) #n_layers\n",
    "opt = torch.optim.Adam(model.parameters(),lr=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# GraphSage\n",
    "best_accuracy = 0\n",
    "best_model_path = 'model.pt'\n",
    "epoch_losses_train = []\n",
    "plot_loss_valid = []\n",
    "train_acc = []\n",
    "valid_acc = []\n",
    "dur = []\n",
    "\n",
    "for epoch in range(200):\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    for step, (input_nodes, output_nodes, bipartites) in enumerate(train_dataloader):\n",
    "        inputs = node_features[input_nodes]\n",
    "        labels = node_labels[output_nodes]\n",
    "        logits = model(bipartites, inputs)\n",
    "        predictions = F.log_softmax(logits,dim=1)\n",
    "\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        loss_epoch += loss.detach().item()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        accuracy = accuracy_score(labels.numpy(), predictions.argmax(1).detach().numpy())\n",
    "        accuracy_epoch += accuracy\n",
    "    accuracy_epoch /= (step + 1)\n",
    "    loss_epoch /= (step + 1)\n",
    "    epoch_losses_train.append(loss_epoch)\n",
    "    train_acc.append(accuracy_epoch)\n",
    "    print('Epoch: {}, Training Accuracy: {:.3f}, Training Loss: {:.3f}'.format(epoch, accuracy_epoch, loss_epoch))\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for input_nodes, output_nodes, bipartites in valid_dataloader:\n",
    "            inputs = node_features[input_nodes]\n",
    "            labels.append(node_labels[output_nodes].numpy())\n",
    "            predictions.append(F.log_softmax(model(bipartites, inputs),dim=1).argmax(1).numpy())\n",
    "            valid_logits = model(bipartites, inputs)\n",
    "            valid_labels = node_labels[output_nodes]\n",
    "            valid_loss = F.cross_entropy(valid_logits, valid_labels)\n",
    "\n",
    "        predictions = np.concatenate(predictions)\n",
    "        labels = np.concatenate(labels)\n",
    "        \n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        dur.append(time.time() - t0)\n",
    "        print('Epoch: {}, Validation Accuracy: {:.3f}, Validation Loss: {:.3f}, Time: {:.4f}'.format(epoch, accuracy, valid_loss.item(), np.mean(dur)))\n",
    "        valid_acc.append(accuracy.item())\n",
    "        plot_loss_valid.append(valid_loss.item())\n",
    "    \n",
    "torch.save(model.state_dict(), best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(epoch_losses_train, label='Training Loss')\n",
    "plt.plot(plot_loss_valid, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(valid_acc, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "print('Classification Accuracy validation set {}'.format(accuracy_score(valid_labels,predictions)))\n",
    "print('-------------------------------------------------------------')\n",
    "print('Confusion Matrix validation set:')\n",
    "print(confusion_matrix(valid_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, plot_roc_curve\n",
    "\n",
    "roc_auc_score(valid_labels,predictions)\n",
    "#plot_roc_curve(logits, X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Machine Learning Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "f =  pd.get_dummies(features)\n",
    "#x = df.drop(columns='y')\n",
    "x_train, x_test, y_train, y_test = train_test_split(feat,f, test_size = 0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "x_train_tf = tf.convert_to_tensor(x_train)\n",
    "x_test_tf = tf.convert_to_tensor(x_test)\n",
    "y_train_tf = tf.convert_to_tensor(y_train)\n",
    "y_test_tf = tf.convert_to_tensor(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "#opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(x_train_tf, y_train_tf,validation_data=(x_test_tf,y_test_tf), epochs=50, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],label = 'Training Loss', color = 'blue')\n",
    "plt.plot(history.history['val_loss'],label = 'Validation Loss', color = 'red')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Binary Cross-Entropy Loss')\n",
    "plt.title('Loss per Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='validation accuracy')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_y = np.empty((len(features),1))\n",
    "\n",
    "for i in range(len(features)):\n",
    "    if features.iloc[i] == 1:\n",
    "        svm_y[i] = 1\n",
    "    else:\n",
    "        svm_y[i] = -1\n",
    "\n",
    "svm_y.astype(int)\n",
    "x_train, x_test, y_train, y_test = train_test_split(feat,svm_y, test_size = 0.6, shuffle=True)\n",
    "\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(x_train, y_train)\n",
    "print('Training Accuracy: 'clf.score(x_train, y_train))\n",
    "print('Validation Accuracy: 'clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Generate the Test Graph and prepare Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.age = df_test.age.apply(lambda x: 0 if x < 25 else(1 if x < 35 else(2 if x < 50 else(3 if x < 65 else 4))))\n",
    "\n",
    "#df.job = df.job.apply(lambda x: 0 if x == 'unemployed' else(1 if x == 'services' \\\n",
    "#                            else(2 if x == 'management' else(3 if x == 'blue-collar' \\\n",
    "#                                else(4 if x == 'self-employed' else(5 if x == 'technician' \\\n",
    "#                                    else(6 if x == 'entrepreneur' else(7 if x == 'admin.' \\\n",
    "#                        else(8 if x =='student' else(9 if x == 'housemaid' \\\n",
    "#                            else(10 if x == 'retired' else 11)))))))))))\n",
    "\n",
    "#df.job = df.job.apply(lambda x: 0 if x == 'unemployed' or 'unknown' else(1 if x == 'services' \\\n",
    "#                        or x == 'management' or x == 'admin.' else(2 if x == 'blue-collar' or x == 'technician' \\\n",
    "#                                    or x == 'housemaid' else(3 if x == 'self-employed' or x == 'entrepreneur' \\\n",
    "#                                        else(4 if x == 'student' else 5)))))\n",
    "\n",
    "df_test.job = df_test.job.apply(lambda x: 0 if x == 'student' else(2 if x == 'retired' else(3 if x == 'unemployed' or x == 'unknown' else 1)))\n",
    "\n",
    "\n",
    "df_test.marital = df_test.marital.apply(lambda x: 0 if x == 'single' else(1 if x == 'married' else 2))\n",
    "\n",
    "df_test.education = df_test.education.apply(lambda x: 0 if x == 'primary' else(1 if x == 'secondary' else(2 if x == 'tertiary' else 3)))\n",
    "\n",
    "df_test.default = df_test.default.apply(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "df_test.balance = df_test.balance.apply(lambda x: 0 if x < 0 else(1 if x < 69. else(2 if x < 444. else(3 if x < 1480 else 4))))\n",
    "\n",
    "df_test.housing = df_test.housing.apply(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "df_test.loan = df_test.loan.apply(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "df_test.contact = df_test.contact.apply(lambda x: 0 if x == 'telephone' else(1 if x == 'cellular' else 2))\n",
    "\n",
    "df_test.duration = df_test.duration.apply(lambda x: 0 if x < 104. else(1 if x < 185 else(2 if x < 329 else 3)))\n",
    "\n",
    "df_test.pdays = df_test.pdays.apply(lambda x: 1 if x > 150 or x == -1 else 0)\n",
    "\n",
    "df_test.poutcome = df_test.poutcome.apply(lambda x: 0 if x == 'failure' else(1 if x == 'success' else 2))\n",
    "\n",
    "df_test.y = df_test.y.apply(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "df_test.drop(columns = ['day','month'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genvars = df_test.drop(columns=['previous','pdays','campaign','duration','contact','loan','default','poutcome','y'])\n",
    "genvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age\n",
    "age_alpha0 = 0.90\n",
    "age_beta1 = 0.80\n",
    "age_beta2 = 0.60\n",
    "age_beta3 = 0.40\n",
    "age_beta4 = 0.20\n",
    "\n",
    "aff_age = np.array([[age_alpha0,age_beta1,age_beta2,age_beta3,age_beta4],\n",
    "                    [age_beta1,age_alpha0,age_beta1,age_beta2,age_beta3],\n",
    "                    [age_beta2,age_beta1,age_alpha0,age_beta1,age_beta2],\n",
    "                    [age_beta3,age_beta2,age_beta1,age_alpha0,age_beta1],\n",
    "                    [age_beta4,age_beta3,age_beta2,age_beta1,age_alpha0]])\n",
    "\n",
    "\n",
    "# job\n",
    "\n",
    "job_alpha0 = 0.90 # self\n",
    "job_beta_wf = 0.60 # workforce\n",
    "job_beta_nwf = 0.60 # not worforce\n",
    "\n",
    "#aff_job = np.array([[job_alpha0, job_beta_wf , job_beta_wf , job_beta_wf , job_beta_nwf, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_alpha0, job_beta_wf, job_beta_wf, job_beta_nwf, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_beta_wf, job_alpha0, job_beta_wf, job_beta_nwf, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_beta_wf, job_beta_wf, job_alpha0, job_beta_nwf, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_beta_wf, job_beta_wf, job_beta_wf, job_alpha0, job_beta_nwf],\n",
    "#                    [job_beta_nwf, job_beta_wf, job_beta_wf, job_beta_wf, job_beta_nwf, job_alpha0]])\n",
    "\n",
    "# employment\n",
    "emp_alpha0 = 0.90 # self\n",
    "emp_beta_wf = 0.75 # beta workforce / employed / unemployed vs student\n",
    "emp_beta_ret = 0.70 # beta retired vs workforce\n",
    "emp_beta_sr = 0.20 # gen gap student / retired\n",
    "\n",
    "aff_job = np.array([[emp_alpha0,emp_beta_wf,emp_beta_sr,emp_beta_wf],\n",
    "                    [emp_beta_wf,emp_alpha0,emp_beta_ret,emp_beta_wf],\n",
    "                    [emp_beta_sr,emp_beta_ret,emp_alpha0,emp_beta_ret],\n",
    "                    [emp_beta_wf,emp_beta_wf,emp_beta_ret,emp_alpha0]])\n",
    "\n",
    "\n",
    "# marital\n",
    "\n",
    "mar_alpha0 = 0.85\n",
    "mar_beta1 = 0.65\n",
    "\n",
    "aff_mar = np.array([[mar_alpha0, mar_beta1, mar_beta1],\n",
    "                    [mar_beta1, mar_alpha0, mar_beta1],\n",
    "                    [mar_beta1, mar_beta1, mar_alpha0]])\n",
    "\n",
    "# education\n",
    "edu_alpha0 = 0.85\n",
    "edu_beta1 = 0.70\n",
    "edu_beta2 = 0.55\n",
    "edu_beta3 = 0.40\n",
    "\n",
    "aff_edu = np.array([[edu_alpha0,edu_beta1,edu_beta2,edu_beta3],\n",
    "                    [edu_beta1,edu_alpha0,edu_beta1,edu_beta2],\n",
    "                    [edu_beta2,edu_beta1,edu_alpha0,edu_beta1],\n",
    "                    [edu_beta3,edu_beta2,edu_beta1,edu_alpha0]])\n",
    "\n",
    "\n",
    "# balance\n",
    "inc_alpha0 = 0.85\n",
    "inc_beta1 = 0.70\n",
    "inc_beta2 = 0.60\n",
    "inc_beta3 = 0.50\n",
    "inc_beta4 = 0.40\n",
    "inc_beta5 = 0.25\n",
    "\n",
    "aff_bal = np.array([[inc_alpha0,inc_beta1,inc_beta2,inc_beta3,inc_beta4],\n",
    "                    [inc_beta1,inc_alpha0,inc_beta1,inc_beta2,inc_beta3],\n",
    "                    [inc_beta2,inc_beta1,inc_alpha0,inc_beta1,inc_beta2],\n",
    "                    [inc_beta3,inc_beta2,inc_beta1,inc_alpha0,inc_beta1],\n",
    "                    [inc_beta4,inc_beta3,inc_beta2,inc_beta2,inc_alpha0]])\n",
    "\n",
    "# housing\n",
    "hous_alpha0 = 0.60\n",
    "hous_beta1 = 0.40\n",
    "\n",
    "aff_hous = np.array([[hous_alpha0,hous_beta1],\n",
    "                     [hous_beta1,hous_alpha0]])\n",
    "\n",
    "# outcome\n",
    "\n",
    "y_alpha0 = 0.95\n",
    "y_beta1 = 0.25\n",
    "\n",
    "aff_y = np.array([[y_alpha0,y_beta1],\n",
    "                  [y_beta1,y_alpha0]])\n",
    "\n",
    "aff = {}\n",
    "aff = {0:aff_age, 1:aff_job ,2:aff_mar ,3:aff_edu ,4:aff_bal ,5:aff_hous}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = genvars.to_numpy()\n",
    "x = x.astype(int)\n",
    "x = x.T\n",
    "\n",
    "P_u_v = np.empty((len(x.T),len(x.T)))\n",
    "prob_u_v = np.empty((len(x),1))\n",
    "u = np.empty((len(x),1))\n",
    "v = np.empty((len(x),1))\n",
    "\n",
    "# create probability for connection between u and v\n",
    "for i in range(len(x.T)):\n",
    "    u = x[:,i]\n",
    "\n",
    "    for k in range(len(x.T)):\n",
    "        v = x[:,k]\n",
    "\n",
    "        for j in range(len(x)):\n",
    "            aff_current = aff[j]\n",
    "            prob_u_v[j] = aff_current[u[j],v[j]]\n",
    "\n",
    "        P_u_v[i,k] = np.prod(prob_u_v) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.triu(P_u_v,1)\n",
    "\n",
    "for i in range(len(P_u_v)):\n",
    "    for j in range(len(P_u_v)):\n",
    "        if A[i,j] > np.random.rand():\n",
    "            A[i,j] = 1\n",
    "        else:\n",
    "            A[i,j] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A + A.T\n",
    "np.sum(A) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_test = nx.from_numpy_matrix(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.Series(df_test.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Test Data to dgl Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_dgl_test = dgl.from_networkx(G_test)\n",
    "feat_test = df_test.drop(columns=['y'])\n",
    "#feat_test = pd.get_dummies(feat_test)\n",
    "scale = StandardScaler()\n",
    "feat_test = pd.DataFrame(scale.fit_transform(feat_test))\n",
    "\n",
    "embedding_test = torch.tensor(feat_test.values,dtype=torch.float)\n",
    "\n",
    "G_dgl_test.ndata['feat'] =  embedding_test\n",
    "#G_dgl.ndata['train_mask'] = torch.zeros(len(G_dgl.nodes()), dtype=torch.bool).bernoulli(0.2)\n",
    "G_dgl_test.ndata['label'] = torch.tensor(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = G_dgl_test.ndata['feat']\n",
    "node_labels = G_dgl_test.ndata['label']\n",
    "test_nids = G_dgl_test.nodes()\n",
    "n_features = node_features.shape[1]\n",
    "n_labels = int(node_labels.max().item() + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, graph, input_features, batch_size):\n",
    "    nodes = torch.arange(graph.number_of_nodes())\n",
    "    \n",
    "    sampler = dgl.dataloading.MultiLayerNeighborSampler([None])  # one layer at a time, taking all neighbors\n",
    "    dataloader = dgl.dataloading.NodeDataLoader(\n",
    "        graph, nodes, sampler,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for l, layer in enumerate(model.layers):\n",
    "            # Allocate a buffer of output representations for every node\n",
    "            # Note that the buffer is on CPU memory.\n",
    "            output_features = torch.zeros(\n",
    "                graph.number_of_nodes(), model.n_hidden if l != model.n_layers - 1 else model.n_classes)\n",
    "\n",
    "            for input_nodes, output_nodes, bipartites in tqdm.tqdm(dataloader):\n",
    "                bipartite = bipartites[0].to(torch.device('cpu'))\n",
    "\n",
    "                x = input_features[input_nodes]\n",
    "\n",
    "                # the following code is identical to the loop body in model.forward()\n",
    "                x = layer(bipartite, x)\n",
    "                if l != model.n_layers - 1:\n",
    "                    x = F.relu(x)\n",
    "                    \n",
    "                elif l == model.n_layers - 1:\n",
    "                    x = F.log_softmax(x,dim=1)\n",
    "\n",
    "                output_features[output_nodes] = x.cpu()\n",
    "            input_features = output_features\n",
    "    return output_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained GraphSage model parameters and get Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))\n",
    "all_predictions = inference(model, G_dgl_test, node_features, 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = all_predictions[test_nids].argmax(1)\n",
    "test_labels = node_labels[test_nids]\n",
    "test_accuracy = sklearn.metrics.accuracy_score(test_predictions.numpy(), test_labels.numpy())\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "print('Classification Accuracy test set {}'.format(accuracy_score(test_labels.numpy(),test_predictions.numpy())))\n",
    "print('-------------------------------------------------------------')\n",
    "print('Confusion Matrix test set:')\n",
    "print(confusion_matrix(test_labels.numpy(),test_predictions.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
